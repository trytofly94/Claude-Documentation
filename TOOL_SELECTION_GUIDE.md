# CLAUDE CODE - TOOL SELECTION GUIDE

**Stand:** 4. November 2025
**Version:** 1.0

Teil der [Claude Ecosystem Dokumentation](README.md)

---

## üéØ √úBERBLICK

### Warum dieser Guide?

Mit der wachsenden Zahl an Features in Claude Code stehen Entwickler vor der Frage: **Welches Tool ist das richtige f√ºr meine Aufgabe?**

Du hast die Wahl zwischen:
- **Skills** - Automatisch aktivierte Expertisen
- **Slash Commands** - Manuelle Prompt-Templates
- **Subagenten** - Spezialisierte Mini-Agenten
- **MCP Server** - Externe Integrationen
- **Hooks** - Event-driven Automation

Alle Tools haben √úberschneidungen in ihren F√§higkeiten, aber unterschiedliche St√§rken und ideale Einsatzgebiete.

### Dieser Guide hilft dir:

- ‚úÖ Die richtige Tool-Wahl f√ºr deine Aufgabe zu treffen
- ‚úÖ Overengineering zu vermeiden
- ‚úÖ Tools effektiv zu kombinieren
- ‚úÖ Von einfachen zu komplexen L√∂sungen zu skalieren
- ‚úÖ Anti-Patterns zu erkennen und zu vermeiden

### Die zentrale Regel: "Prompt First"

> **Fang immer mit dem einfachsten Tool an: einem Slash Command (oder direktem Prompt)**

Erst wenn du erkennst, dass du:
- üîÑ **Parallelisierung** brauchst ‚Üí **Subagent**
- ü§ñ **Automatische Ausl√∂sung** willst ‚Üí **Skill**
- üîå **Externe Daten** brauchst ‚Üí **MCP Server**
- ‚ö° **Garantierte Automatisierung** brauchst ‚Üí **Hook**

...solltest du komplexere Tools nutzen.

**Wichtig:** Dieser Guide fokussiert sich auf **WANN** welches Tool nutzen. F√ºr die technischen Details **WIE** Tools implementiert und kombiniert werden, siehe [TOOL_INTERACTIONS.md](TOOL_INTERACTIONS.md).

---

## üìö DIE VIER GRUNDBAUSTEINE

Bevor wir in die Tool-Auswahl einsteigen, ist es wichtig die **vier Grundbausteine** des Agentic Coding zu verstehen:

### 1. Context (Kontext)

**Was wei√ü Claude √ºber dein Projekt?**

- **Dateien:** Code, Dokumentation, Tests
- **CLAUDE.md:** Projekt-Memory mit Architektur & Standards
- **MCP-Daten:** Externe Systeme (Jira, GitHub, Datenbanken)
- **Conversation History:** Vorherige Nachrichten im Chat

**‚ö†Ô∏è Problem: Context Window Limits!**

Jedes Modell hat ein maximales Context Window:
- **Claude Sonnet 4.5:** 200K tokens (Standard)
- **Claude Haiku 4.5:** 200K tokens
- Pro Token: ~4 Zeichen Code oder ~0.75 W√∂rter

Zu viel Context = Performance-Probleme und h√∂here Kosten!

**Best Practice:** Verwende Tools, die Context sparsam nutzen (Skills mit Progressive Disclosure).

---

### 2. Model (Modell)

**Welches Claude-Modell nutzt du?**

- **Claude Sonnet 4.5** (Standard)
  - 77.2% SWE-bench Verified
  - Beste Code-Qualit√§t
  - $3/$15 per million tokens

- **Claude Haiku 4.5** (Schnell/G√ºnstig)
  - 73.3% SWE-bench Verified
  - 4-5x schneller als Sonnet
  - $1/$5 per million tokens

**Wichtig:** Model-Wahl beeinflusst Performance und Kosten. F√ºr einfache Tasks (Code-Reviews, Tests) kann Haiku ausreichen.

---

### 3. Prompt (Eingabe)

**Der fundamentale Baustein!**

> Ohne guten Prompt helfen keine Tools!

Ein guter Prompt:
- ‚úÖ Ist spezifisch und klar
- ‚úÖ Enth√§lt relevanten Context
- ‚úÖ Definiert das gew√ºnschte Ergebnis
- ‚úÖ Gibt Beispiele wenn sinnvoll

**Custom Prompts = Slash Commands**

Slash Commands sind nichts anderes als wiederverwendbare Prompt-Templates!

---

### 4. Tools (Werkzeuge)

**Erweitere Claude's F√§higkeiten**

**Built-in Tools:**
- Read, Write, Edit (Dateien)
- Bash (Shell-Commands)
- Grep, Glob (Suche)
- WebFetch, WebSearch (Web-Zugriff)

**Erweiterte Tools:**
- Skills, Slash Commands, Subagenten (diese Dokumentation)
- MCP Server (externe Integrationen)
- Hooks (Event-driven Automation)

**‚ö†Ô∏è Achtung: Tool-Overload = Context-Pollution!**

Zu viele Tools (besonders MCP Server) k√∂nnen das Context Window √ºberlasten. Nutze sie gezielt!

---

## üîß TOOL-√úBERSICHT (KOMPAKT)

Hier eine schnelle √úbersicht aller verf√ºgbaren Tools:

### Slash Commands

**Was:** Wiederverwendbare Prompt-Templates (Markdown-Dateien)

**Wann:** F√ºr manuelle, wiederholbare Workflows

**Invocation:** User (manuell via `/command-name`)

**Speicherort:** `.claude/commands/` (Projekt) oder `~/.claude/commands/` (Global)

**Beispiel:** `/commit-message`, `/create-component`, `/deploy`

---

### Skills

**Was:** Automatisch aktivierte Expertisen (Progressive Disclosure)

**Wann:** F√ºr wiederkehrende Tasks mit mehreren Schritten, die Claude selbst erkennen soll

**Invocation:** Claude (automatisch basierend auf Description)

**Speicherort:** `.claude/skills/skill-name/SKILL.md`

**Beispiel:** PDF Analyzer, Brand Guidelines Checker, Git Worktree Manager

---

### Subagenten

**Was:** Spezialisierte Mini-Agenten mit eigenen Tools und Prompts

**Wann:** F√ºr parallele oder isolierte Workflows

**Invocation:** Claude oder User (via Slash Command)

**Speicherort:** `.claude/subagents/agent-name.md`

**Beispiel:** Security Scanner, Test Fixer, Parallel Feature Development

---

### MCP Server

**Was:** Externe Integrationen (Datenquellen, APIs)

**Wann:** F√ºr Zugriff auf externe Systeme und Daten

**Invocation:** Claude (automatisch bei Bedarf)

**Konfiguration:** `claude_desktop_config.json` oder `.claude/settings.json`

**Beispiel:** Jira, GitHub, Google Drive, Slack, Salesforce, PostgreSQL

---

### Hooks

**Was:** Event-driven Automation (Shell-Scripts)

**Wann:** F√ºr garantierte Automatisierung (nicht LLM-abh√§ngig)

**Invocation:** System (bei Events wie PreToolUse, PostToolUse)

**Konfiguration:** `.claude/settings.json` ‚Üí `hooks`

**Beispiel:** Auto-Formatting, Security-Checks, Pre-Commit Hooks

---

**F√ºr technische Details zur Implementierung:** Siehe [TOOL_INTERACTIONS.md](TOOL_INTERACTIONS.md)

---

## üå≥ ENTSCHEIDUNGSBAUM

### Visueller Flowchart f√ºr Tool-Auswahl

```mermaid
graph TD
    A[Neue Aufgabe] --> B{Externe Integration n√∂tig?}
    B -->|Ja| C[MCP Server]
    B -->|Nein| D{Muss es parallel laufen?}
    D -->|Ja| E[Subagent]
    D -->|Nein| F{Wiederkehrende Task<br/>mit mehreren Schritten?}
    F -->|Ja| G{Soll Claude automatisch<br/>entscheiden wann?}
    G -->|Ja| H[Skill]
    G -->|Nein| I[Slash Command]
    F -->|Nein| I

    C --> J[Beispiel: Jira, GitHub, DB,<br/>Google Drive, Salesforce]
    E --> K[Beispiel: Parallele Tests,<br/>Multi-Repo Tasks,<br/>Security Scans]
    H --> L[Beispiel: Style Guide,<br/>API Design, QBR,<br/>PDF Analysis]
    I --> M[Beispiel: Git Commit,<br/>UI Component, Deploy,<br/>Code Review]

    style C fill:#ff9999
    style E fill:#99ccff
    style H fill:#99ff99
    style I fill:#ffff99
```

### Erkl√§rung der Entscheidungslogik

#### 1. Externe Integration n√∂tig?

**Frage dich:** Brauchst du Daten oder Funktionen von au√üerhalb deines lokalen Projekts?

**Beispiele:**
- ‚úÖ Jira Issues abrufen
- ‚úÖ Salesforce Daten analysieren
- ‚úÖ Google Drive Dokumente bearbeiten
- ‚úÖ Datenbank-Queries ausf√ºhren
- ‚úÖ Slack Nachrichten senden

**‚Üí MCP Server**

**Wichtig:** F√ºr **lokale Dateien** brauchst du **KEINEN** MCP Server! Nutze die Built-in Tools (Read, Write, Grep, Glob).

---

#### 2. Muss es parallel laufen?

**Frage dich:** Muss die Task in mehreren isolierten Kontexten gleichzeitig ausgef√ºhrt werden?

**Keywords:** "parallel", "gleichzeitig", "mehrere Repos", "batch processing"

**Beispiele:**
- ‚úÖ 10 failing Tests gleichzeitig fixen
- ‚úÖ Security-Scan √ºber mehrere Repositories
- ‚úÖ Parallele Feature-Entwicklung in Git Worktrees
- ‚úÖ Bulk-Operations √ºber viele Dateien

**‚Üí Subagent**

**Vorteil:** Subagenten arbeiten isoliert und k√∂nnen parallel laufen. Jeder Subagent hat seinen eigenen Context.

**Nachteil:** Subagenten verlieren den Haupt-Context (Main Agent). Nicht geeignet wenn Context-Sharing n√∂tig ist.

---

#### 3. Wiederkehrend + Mehrstufig?

**Frage dich:**
- Ist es eine Task mit **mehreren logischen Schritten**?
- Wird sie **h√§ufig wiederholt**?

**Beispiele:**
- ‚úÖ Component erstellen (Datei + Test + Storybook + Export)
- ‚úÖ API Endpoint implementieren (Route + Handler + Validation + Test)
- ‚úÖ Deployment-Prozess (Build + Test + Deploy + Verify)
- ‚úÖ Code Review nach Team-Standards

**‚Üí Skill ODER Slash Command** (Entscheidung in Schritt 4)

---

#### 4. Manuelle vs. Automatische Ausl√∂sung?

**Die finale Entscheidung:**

**‚Üí Skill** wenn:
- ‚úÖ Claude soll **selbst entscheiden** wann relevant
- ‚úÖ Domain-Expertise kodifizieren (Legal, SEO, Brand)
- ‚úÖ Team-Standards durchsetzen
- ‚úÖ User erw√§hnt relevante Keywords ‚Üí Automatische Aktivierung

**‚Üí Slash Command** wenn:
- ‚úÖ Du willst **manuell triggern**
- ‚úÖ Explizite Kontrolle gew√ºnscht
- ‚úÖ Task ist zu spezifisch f√ºr Auto-Activation
- ‚úÖ Primitiv f√ºr Skills/Subagenten

---

#### 5. Garantierte Automatisierung n√∂tig?

**Sonderfall: Hooks**

Wenn du **garantierte Automatisierung** brauchst (nicht LLM-abh√§ngig):

**‚Üí Hook**

**Beispiele:**
- ‚úÖ Auto-Formatting nach jedem Write
- ‚úÖ Production Writes blockieren (PreToolUse)
- ‚úÖ Security-Checks
- ‚úÖ Linting

**Wichtig:** Hooks sind Shell-Scripts, keine LLM-gesteuerte Logik!

---

### Wenn nichts davon zutrifft:

**‚Üí Einfacher Prompt oder Slash Command**

F√ºr einmalige, einfache Tasks brauchst du keine speziellen Tools.

---

## üìä FEATURE-VERGLEICH

Detaillierter Vergleich aller Tools nach wichtigen Kriterien:

| Feature | Skills | Slash Commands | Subagenten | MCP Server | Hooks |
|---------|--------|----------------|------------|------------|-------|
| **Invocation** | Agent (automatisch) | User (manuell) | Agent oder User | Agent (automatisch) | System (Event) |
| **Context-Effizienz** | ‚úÖ Ja (Progressive Disclosure) | ‚úÖ Ja | ‚úÖ Ja (isoliert) | ‚ùå Nein (Context-Window-Explosion) | ‚úÖ N/A |
| **Context-Persistent** | ‚úÖ Ja | ‚úÖ Ja | ‚ùå Nein (Context verloren) | ‚úÖ Ja | ‚úÖ N/A |
| **Modularit√§t** | ‚úÖ‚úÖ Sehr hoch | ‚ö†Ô∏è Mittel | ‚ö†Ô∏è Mittel | ‚úÖ‚úÖ Sehr hoch | ‚ö†Ô∏è Niedrig |
| **Parallelisierbar** | ‚ùå Nein | ‚ùå Nein | ‚úÖ‚úÖ Ja | ‚ùå Nein | ‚úÖ N/A |
| **Kompositionsf√§higkeit** | ‚úÖ‚úÖ Sehr hoch | ‚úÖ‚úÖ Sehr hoch | ‚ö†Ô∏è Begrenzt | ‚úÖ Mittel | ‚ö†Ô∏è Niedrig |
| **Komplexit√§t** | Hoch | Niedrig | Mittel | Mittel | Niedrig |
| **Setup-Aufwand** | Hoch | Niedrig | Mittel | Hoch | Niedrig |
| **Wiederverwendbarkeit** | ‚úÖ‚úÖ Sehr hoch | ‚úÖ‚úÖ Sehr hoch | ‚úÖ Hoch | ‚úÖ‚úÖ Sehr hoch | ‚úÖ Hoch |
| **LLM-abh√§ngig** | ‚úÖ Ja | ‚úÖ Ja | ‚úÖ Ja | ‚úÖ Ja | ‚ùå Nein (garantiert) |
| **Externe Daten** | ‚ö†Ô∏è Via MCP | ‚ö†Ô∏è Via MCP | ‚ö†Ô∏è Via MCP | ‚úÖ‚úÖ Native | ‚ùå Nein |
| **Tool-Isolation** | ‚ùå Nein | ‚ùå Nein | ‚úÖ‚úÖ Ja | ‚ùå Nein | ‚ùå Nein |

### Legende

- ‚úÖ‚úÖ = Exzellent
- ‚úÖ = Gut/Ja
- ‚ö†Ô∏è = Eingeschr√§nkt/Mit Vorsicht
- ‚ùå = Nein/Nicht geeignet
- N/A = Nicht anwendbar

### Detaillierte Erkl√§rungen

#### Context-Effizienz

**Skills: ‚úÖ Progressive Disclosure**
- Stufe 1: Metadata (Name + Description) f√ºr ALLE Skills
- Stufe 2: Full Instructions nur f√ºr relevante Skills
- Stufe 3: Resources (@assets) nur bei Bedarf
- **Ergebnis:** Context-effizient auch bei vielen Skills

**MCP Server: ‚ùå Context-Window-Explosion**
- ALLE MCP Tools und Prompts sofort im Context Window
- Bei vielen MCP Servern: Massives Context-Problem
- **Empfehlung:** Max. 5 MCP Server gleichzeitig

**Slash Commands: ‚úÖ Effizient**
- Nur geladen wenn aufgerufen
- Kein Context-Overhead

**Subagenten: ‚úÖ Isoliert**
- Eigener Context pro Subagent
- Kein Haupt-Context-Pollution

---

#### Context-Persistent

**Was bedeutet das?**
Bleibt der Context zwischen Aufrufen erhalten?

**Skills/Commands/MCP: ‚úÖ Ja**
- Haupt-Context bleibt intakt
- K√∂nnen auf Conversation History zugreifen

**Subagenten: ‚ùå Nein**
- Verlieren Haupt-Context nach Delegation
- M√ºssen relevante Infos explizit √ºbergeben bekommen
- Return nur Results, nicht den vollen Context

---

#### Parallelisierbarkeit

**Nur Subagenten: ‚úÖ‚úÖ**
- K√∂nnen parallel laufen
- Ideal f√ºr Batch-Processing

**Alle anderen: ‚ùå**
- Laufen sequenziell im Haupt-Context

---

#### Kompositionsf√§higkeit

**Skills & Slash Commands: ‚úÖ‚úÖ Sehr hoch**
- K√∂nnen alles aufrufen (Skills, Commands, Subagenten, MCP)
- H√∂chste Ebene der Kompositionshierarchie

**MCP Server: ‚úÖ Mittel**
- Sollten NICHT Skills aufrufen (niedrigere Ebene)
- K√∂nnen von allen anderen genutzt werden

**Subagenten: ‚ö†Ô∏è Begrenzt**
- K√∂nnen KEINE anderen Subagenten aufrufen (technische Limitation)
- K√∂nnen Skills, Commands, MCP nutzen

**Hooks: ‚ö†Ô∏è Niedrig**
- Shell-Scripts, keine LLM-Logik
- K√∂nnen externe Scripts aufrufen

---

#### LLM-abh√§ngig

**Hooks: ‚ùå Nein (garantiert)**
- Einzige Tools, die **garantiert** ausgef√ºhrt werden
- Nicht von LLM-Entscheidungen abh√§ngig
- Ideal f√ºr kritische Automatisierung (Security, Formatting)

**Alle anderen: ‚úÖ Ja**
- Claude entscheidet wann und wie sie genutzt werden
- Kann fehlschlagen wenn Prompt unklar

---

## üéØ USE CASE MATRIX

Wann welches Tool nutzen? Hier sind die wichtigsten Use Cases mit konkreten Beispielen:

---

## SKILLS - Automatisches Verhalten

### Wann nutzen

‚úÖ **Claude soll selbst erkennen** wann relevant
‚úÖ **Wiederkehrende Multi-Step-Workflows**
‚úÖ **Domain-Expertise kodifizieren** (Legal, SEO, Brand Guidelines)
‚úÖ **Team-Standards durchsetzen** (Code Style, Commit Messages, API Design)
‚úÖ **Automatische Reaktion auf Keywords** im User-Prompt

### Wann NICHT nutzen

‚ùå **Einmalige Tasks** (zu viel Overhead)
‚ùå **Wenn du explizite Kontrolle brauchst** (nutze Slash Command)
‚ùå **Wenn Context-Window knapp ist** (Skills laden Metadata)
‚ùå **Zu einfache Tasks** (1-Schritt-Operations)

---

### Praxisbeispiel 1: PDF-Text automatisch extrahieren

**Szenario:** Du arbeitest oft mit PDFs und willst dass Claude automatisch Text extrahiert wenn du PDFs erw√§hnst.

**L√∂sung: Skill**

```markdown
---
name: PDF Analyzer
description: Extract and analyze text from PDF files. Use when user uploads or references PDFs.
---

# PDF Analyzer Skill

## Instructions

When user mentions or references a PDF file:

1. Detect PDF files in context (uploaded, path mentioned)
2. Extract text using `pdftotext` command
3. Structure content into logical sections
4. Provide analysis based on user request

## Commands

```bash
pdftotext input.pdf output.txt
# or for better formatting:
pdftotext -layout input.pdf output.txt
```

## Example Usage

User: "Analyze the contract.pdf in the documents folder"
‚Üí Skill activates automatically
‚Üí Extracts text from contract.pdf
‚Üí Provides analysis
```

**Workflow:**
1. User: "Schau dir mal budget-report.pdf an"
2. Skill aktiviert automatisch (Keywords: "pdf")
3. Automatische Extraktion mit pdftotext
4. Claude analysiert Inhalt

**Warum Skill und nicht Command?**
- ‚úÖ Automatische Aktivierung (kein manuelles `/pdf` n√∂tig)
- ‚úÖ Wiederkehrend (du arbeitest oft mit PDFs)
- ‚úÖ Multi-Step (Detect ‚Üí Extract ‚Üí Structure ‚Üí Analyze)

---

### Praxisbeispiel 2: Style-Guide-Verletzungen erkennen

**Szenario:** Dein Team hat Brand Guidelines die bei jeder Pr√§sentation/Dokument gepr√ºft werden sollen.

**L√∂sung: Skill mit @assets**

```markdown
---
name: Brand Compliance Checker
description: Check for brand guideline violations in documents and designs. Use when reviewing content, presentations, or marketing materials.
---

# Brand Compliance Skill

## Instructions

When user creates or reviews content that could violate brand guidelines:

1. Load brand guidelines from @assets/brand-guide.pdf
2. Check for violations:
   - Logo usage (size, placement, variants)
   - Color codes (hex values must match exactly)
   - Font families and sizes
   - Tone of voice in copy
3. Flag violations with severity (Critical/Warning/Info)
4. Suggest corrections

## Brand Assets

@assets/brand-guide.pdf
@assets/approved-logos/
@assets/color-palette.json

## Example Check

```json
{
  "violations": [
    {
      "type": "logo",
      "severity": "critical",
      "description": "Logo used in old variant",
      "correction": "Use logo-2024.svg from approved-logos/"
    },
    {
      "type": "color",
      "severity": "warning",
      "description": "Blue shade #1E90FF not in palette",
      "correction": "Use brand blue #1A73E8 instead"
    }
  ]
}
```
```

**Workflow:**
1. User: "Erstelle Pr√§sentation f√ºr Q4 Review"
2. Skill aktiviert automatisch (Keywords: "Pr√§sentation")
3. L√§dt Brand Guidelines aus @assets/
4. Claude erstellt Pr√§sentation
5. Skill pr√ºft automatisch gegen Guidelines
6. Report mit Violations

**Warum Skill?**
- ‚úÖ Team-Standard (jeder soll Guidelines einhalten)
- ‚úÖ Automatische Pr√ºfung (kein manuelles `/check-brand` n√∂tig)
- ‚úÖ Nutzt @assets f√ºr Referenz-Dokumente

---

### Praxisbeispiel 3: Git Work Trees verwalten

**Szenario:** Dein Team nutzt Git Worktrees f√ºr parallele Feature-Entwicklung. Es gibt mehrere Operations (create, remove, list, merge).

**L√∂sung: Skill orchestriert Slash Commands**

```markdown
---
name: Git Worktree Manager
description: Manage git worktrees (create, remove, list, merge). Use when user needs parallel feature development or wants to work on multiple branches simultaneously.
---

# Worktree Manager Skill

## Available Commands

- `/create-worktree <feature-name>` - Create new worktree
- `/remove-worktree <feature-name>` - Remove worktree
- `/list-worktrees` - List all worktrees
- `/merge-worktree <feature-name>` - Merge worktree back to main

## Instructions

Based on user request, invoke appropriate slash command:

1. **Create**: "Setup worktree f√ºr feature X"
   ‚Üí Invoke `/create-worktree X`

2. **List**: "Zeig mir alle worktrees"
   ‚Üí Invoke `/list-worktrees`

3. **Remove**: "L√∂sche worktree f√ºr X"
   ‚Üí Invoke `/remove-worktree X`

4. **Merge**: "Merge worktree X zur√ºck"
   ‚Üí Invoke `/merge-worktree X`

## Workflow Example

User: "Ich brauche parallele Worktrees f√ºr login-feature und dashboard-redesign"
‚Üí Skill erkennt Worktree-Request
‚Üí Ruft `/create-worktree login-feature` auf
‚Üí Ruft `/create-worktree dashboard-redesign` auf
‚Üí Best√§tigt beide Worktrees erstellt
```

**Workflow:**
1. User: "Setup worktree f√ºr authentication"
2. Skill aktiviert (Keywords: "worktree")
3. Skill ruft `/create-worktree authentication` auf
4. Worktree erstellt, Branch angelegt

**Warum Skill und nicht nur Commands?**
- ‚úÖ Nat√ºrliche Sprache (User muss nicht `/create-worktree` kennen)
- ‚úÖ Intelligente Orchestrierung (Skill w√§hlt richtigen Command)
- ‚úÖ Multi-Step m√∂glich (z.B. create + setup dependencies)

---

### Praxisbeispiel 4: API Design nach Team-Standards

**Szenario:** Dein Team hat strikte REST API Design Guidelines die bei jedem neuen Endpoint gelten.

**L√∂sung: Skill mit CLAUDE.md Integration**

```markdown
---
name: API Design Reviewer
description: Review and enforce REST API design standards. Use when creating or reviewing API endpoints.
---

# API Design Reviewer Skill

## Instructions

When user creates new API endpoints:

1. Read @CLAUDE.md for project API standards
2. Review endpoint design against standards:
   - URL structure (RESTful naming)
   - HTTP methods (correct usage)
   - Response formats (consistent JSON structure)
   - Error handling (standard error codes)
   - Authentication (required headers)
   - Rate limiting (where applicable)
3. Flag violations
4. Suggest improvements

## Standards to Check

From @CLAUDE.md:
- `/api/v1/{resource}` naming
- POST for creation, PUT for full update, PATCH for partial
- Always return 201 with Location header on POST
- Errors in format: `{"error": {"code": "...", "message": "..."}}`
- Pagination with `?page=1&limit=20`

## Example Review

**Endpoint:** `POST /users/create`

**Violations:**
‚ùå URL should be `POST /api/v1/users` (no /create suffix)
‚ùå Missing 201 status code in implementation
‚ùå Missing Location header

**Corrected:**
```typescript
// POST /api/v1/users
app.post('/api/v1/users', async (req, res) => {
  const user = await createUser(req.body);
  res.status(201)
     .header('Location', `/api/v1/users/${user.id}`)
     .json(user);
});
```
```

**Warum Skill?**
- ‚úÖ Team-Standard (jeder neue Endpoint sollte gepr√ºft werden)
- ‚úÖ Automatisch (Claude pr√ºft selbst w√§hrend Entwicklung)
- ‚úÖ Nutzt @CLAUDE.md f√ºr Projekt-Standards

---

## SLASH COMMANDS - Manuelle, Wiederverwendbare Prompts

### Wann nutzen

‚úÖ **Wiederholbare Workflows** die du **manuell triggern** willst
‚úÖ **Als Primitiv f√ºr Skills/Subagenten** (Building Blocks)
‚úÖ **Orchestrierung mehrerer Schritte** mit klarer Sequenz
‚úÖ **Immer als erster Schritt** ("Prompt First"!)
‚úÖ **Wenn du explizite Kontrolle** brauchst

### Wann NICHT nutzen

‚ùå **Wenn Claude automatisch entscheiden soll** ‚Üí Skill
‚ùå **F√ºr externe Daten** ‚Üí MCP Server
‚ùå **F√ºr Parallelisierung** ‚Üí Subagent
‚ùå **F√ºr garantierte Automatisierung** ‚Üí Hook

---

### Praxisbeispiel 1: Git Commit Messages generieren

**Szenario:** Du willst Conventional Commit Messages f√ºr staged changes generieren.

**L√∂sung: Slash Command**

```markdown
---
name: commit-message
description: Generate conventional commit message for staged changes
---

# Commit Message Generator

Generate a conventional commit message following our team standards.

## Steps

1. Run `git diff --staged` to see changes
2. Analyze type of changes:
   - New features ‚Üí `feat:`
   - Bug fixes ‚Üí `fix:`
   - Documentation ‚Üí `docs:`
   - Refactoring ‚Üí `refactor:`
   - Tests ‚Üí `test:`
   - Build/CI ‚Üí `chore:`
3. Identify scope (component/module affected)
4. Write concise subject (max 50 chars)
5. Add body with "why" (if needed)

## Format

```
<type>(<scope>): <subject>

<body>

<footer>
```

## Example

```
feat(auth): add OAuth2 login flow

Implements OAuth2 authentication with Google and GitHub providers.
Includes token refresh mechanism and secure cookie storage.

Closes #123
```

## Output

Present the generated commit message and ask if user wants to commit now.
```

**Workflow:**
1. User macht Code-√Ñnderungen
2. User: `/commit-message`
3. Command generiert Message nach Standards
4. User commitet (oder Claude fragt nach)

**Warum Command und nicht Skill?**
- ‚úÖ Manuelle Kontrolle (nicht bei jedem Commit automatisch)
- ‚úÖ Expliziter Trigger (User entscheidet wann)
- ‚úÖ Einfacher Workflow (1-Schritt)

---

### Praxisbeispiel 2: React-Komponente erstellen

**Szenario:** Du erstellst oft neue React Components mit TypeScript + Tests + Storybook.

**L√∂sung: Slash Command mit Argumenten**

```markdown
---
name: create-component
description: Create React component with TypeScript, tests, and Storybook
---

# React Component Creator

Create a new React component: **$ARGUMENTS**

## Steps

1. Read @CLAUDE.md for project structure
2. Create component file: `src/components/$ARGUMENTS/$ARGUMENTS.tsx`
3. Create TypeScript interface for props
4. Implement component with:
   - Proper typing
   - JSDoc comments
   - Export default
5. Create test file: `src/components/$ARGUMENTS/$ARGUMENTS.test.tsx`
   - Test rendering
   - Test props
   - Test user interactions
6. Create Storybook file: `src/components/$ARGUMENTS/$ARGUMENTS.stories.tsx`
   - Default story
   - Variants for different props
7. Export from index: `src/components/index.ts`

## Component Template

```typescript
import React from 'react';

interface ${ARGUMENTS}Props {
  // Props here
}

/**
 * $ARGUMENTS component
 * @description ...
 */
export const $ARGUMENTS: React.FC<${ARGUMENTS}Props> = (props) => {
  return (
    <div className="$ARGUMENTS">
      {/* Component content */}
    </div>
  );
};

export default $ARGUMENTS;
```

## Usage Example

`/create-component Button`
‚Üí Creates Button.tsx, Button.test.tsx, Button.stories.tsx
```

**Workflow:**
1. User: `/create-component SearchBar`
2. Command erstellt alle Files:
   - `SearchBar.tsx` (Component)
   - `SearchBar.test.tsx` (Tests)
   - `SearchBar.stories.tsx` (Storybook)
   - Export in `index.ts`

**Warum Command?**
- ‚úÖ Manuelle Kontrolle (Component-Erstellung ist explizite Action)
- ‚úÖ Akzeptiert Argumente ($ARGUMENTS = Component Name)
- ‚úÖ Multi-Step aber sequenziell
- ‚úÖ Wiederholbar

**K√∂nnte es ein Skill sein?**
‚ö†Ô∏è Nein, weil:
- User will explizit Components erstellen (kein Auto-Detect)
- Zu spezifisch f√ºr automatische Aktivierung

---

### Praxisbeispiel 3: Deployment-Prozess

**Szenario:** Multi-Step Deployment mit Build, Test, Deploy, Verify.

**L√∂sung: Slash Command orchestriert Pipeline**

```markdown
---
name: deploy
description: Deploy application to production (build, test, deploy, verify)
---

# Production Deployment

Deploy to production with full verification pipeline.

## Pre-Flight Checks

1. Verify git status is clean
2. Verify on main branch
3. Verify all tests pass locally
4. Verify no uncommitted changes

## Deployment Steps

1. **Build:**
   ```bash
   npm run build:production
   ```

2. **Test:**
   ```bash
   npm run test:all
   npm run test:e2e
   ```

3. **Deploy:**
   ```bash
   # Tag release
   git tag -a v$(date +%Y%m%d-%H%M) -m "Production deployment"
   git push origin --tags

   # Deploy
   npm run deploy:production
   ```

4. **Verify:**
   ```bash
   # Health check
   curl https://api.production.com/health

   # Smoke tests
   npm run test:smoke:production
   ```

5. **Notify:**
   - Log deployment to monitoring
   - Post to Slack #deployments channel
   - Update deployment dashboard

## Rollback Plan

If verification fails:
```bash
npm run rollback:production
```

## Output

Provide deployment summary:
- Version deployed
- Timestamp
- Health check results
- Smoke test results
```

**Workflow:**
1. User: `/deploy`
2. Command f√ºhrt Pipeline aus:
   - Build ‚úÖ
   - Tests ‚úÖ
   - Deploy ‚úÖ
   - Verify ‚úÖ
3. Success oder Rollback

**Warum Command?**
- ‚úÖ Explizite Kontrolle (Production Deployment ist kritisch!)
- ‚úÖ Multi-Step aber sequenziell
- ‚úÖ Klare Rollback-Strategie
- ‚úÖ Nicht automatisierbar (zu riskant)

---

### Praxisbeispiel 4: Code Review nach Checkliste

**Szenario:** Du willst Code-Reviews nach Team-Checkliste durchf√ºhren.

**L√∂sung: Slash Command mit CLAUDE.md**

```markdown
---
name: code-review
description: Perform code review using team checklist from CLAUDE.md
---

# Code Review

Perform comprehensive code review using team standards.

## Review Checklist

From @CLAUDE.md:

### Code Quality
- [ ] No commented-out code
- [ ] No console.log/print statements
- [ ] Meaningful variable names
- [ ] Functions < 50 lines
- [ ] Files < 1000 lines

### Testing
- [ ] Unit tests for new functions
- [ ] Integration tests for API endpoints
- [ ] Edge cases covered
- [ ] Mocks used appropriately

### Security
- [ ] No hardcoded secrets
- [ ] Input validation present
- [ ] SQL injection prevention
- [ ] XSS prevention

### Performance
- [ ] No N+1 queries
- [ ] Large lists paginated
- [ ] Database indices on foreign keys
- [ ] Caching where appropriate

### Documentation
- [ ] Public functions have JSDoc/docstrings
- [ ] README updated if needed
- [ ] CHANGELOG entry added

## Process

1. Read git diff or specified files
2. Go through checklist systematically
3. Flag violations with severity
4. Suggest concrete improvements
5. Provide overall score (1-10)

## Output Format

```markdown
# Code Review Results

## Summary
- Files reviewed: 5
- Violations: 3 critical, 7 warnings
- Score: 6/10

## Critical Issues
1. **Security:** Hardcoded API key in config.ts:42
2. **Testing:** No tests for new PaymentService
3. **Performance:** N+1 query in UserController.getAllWithOrders()

## Warnings
...

## Suggestions
...
```
```

**Workflow:**
1. User: `/code-review`
2. Command liest @CLAUDE.md f√ºr Team-Standards
3. Analysiert staged changes oder aktuellen Branch
4. Geht Checkliste durch
5. Report mit Violations + Score

**Warum Command?**
- ‚úÖ Expliziter Trigger (Review auf Anfrage)
- ‚úÖ Nutzt @CLAUDE.md f√ºr Team-Standards
- ‚úÖ Multi-Step Analyse

**K√∂nnte es ein Skill sein?**
‚ö†Ô∏è Ja, wenn du willst dass Claude automatisch bei PRs reviewed. Aber:
- Commands geben dir mehr Kontrolle
- Du entscheidest wann Review stattfindet

---

## SUBAGENTEN - Parallele & Isolierte Workflows

### Wann nutzen

‚úÖ **Keyword: "parallel"** in der Anforderung
‚úÖ **Isolierte Execution** ohne Context-Pollution
‚úÖ **Security-kritische Ops** mit eingeschr√§nkten Tools
‚úÖ **Gro√üe Codebase-Scans** die lange dauern
‚úÖ **Batch-Processing** √ºber viele Dateien/Repos

### Wann NICHT nutzen

‚ùå **Wenn Context-Sharing n√∂tig ist** (Subagents verlieren Main-Context)
‚ùå **Wenn keine Parallelisierung n√∂tig** (unn√∂tiger Overhead)
‚ùå **F√ºr verschachtelte Subagents** (technisch nicht m√∂glich!)
‚ùå **Wenn du einfache sequenzielle Logik brauchst** (nutze Command/Skill)

---

### Praxisbeispiel 1: Umfassende Security-Audits

**Szenario:** Vollst√§ndiger Security-Scan der Codebase mit Read-Only Access.

**L√∂sung: Subagent mit Tool-Isolation**

```markdown
---
name: security-scanner
description: Scan codebase for security vulnerabilities with read-only access
tools: ["Read", "Grep", "Glob"]  # Nur Lese-Zugriff!
model: claude-haiku-4.5  # Schneller + g√ºnstiger f√ºr Scans
---

# Security Scanner Subagent

Comprehensive security audit of codebase.

## Focus Areas

### 1. OWASP Top 10
- SQL Injection
- XSS (Cross-Site Scripting)
- CSRF (Cross-Site Request Forgery)
- Authentication/Authorization issues
- Sensitive Data Exposure
- Security Misconfiguration

### 2. Common Vulnerabilities
- Hardcoded secrets (API keys, passwords)
- Insecure dependencies
- Missing input validation
- Unsafe eval/exec usage
- Path traversal vulnerabilities

### 3. Best Practices
- HTTPS enforcement
- Secure cookies (HttpOnly, Secure, SameSite)
- Password hashing (bcrypt, not MD5)
- Rate limiting
- CORS configuration

## Scan Process

1. **Secrets Scan:**
   ```bash
   grep -r "API_KEY\|SECRET\|PASSWORD\|TOKEN" --include="*.ts" --include="*.js"
   ```

2. **SQL Injection:**
   ```bash
   grep -r "query.*\+\|execute.*\+" --include="*.ts" --include="*.js"
   ```

3. **XSS Vulnerabilities:**
   ```bash
   grep -r "innerHTML\|dangerouslySetInnerHTML" --include="*.tsx" --include="*.jsx"
   ```

4. **Dependency Check:**
   ```bash
   npm audit --json
   ```

## Report Format

```json
{
  "summary": {
    "total_files_scanned": 245,
    "critical_issues": 2,
    "high_issues": 5,
    "medium_issues": 12,
    "low_issues": 8
  },
  "critical": [
    {
      "file": "src/config.ts",
      "line": 42,
      "type": "hardcoded_secret",
      "description": "Hardcoded API key exposed",
      "remediation": "Move to environment variable"
    }
  ]
}
```
```

**Workflow:**
1. Main Agent: "F√ºhre Security-Audit durch"
2. Delegiert an Security Scanner Subagent
3. Subagent scannt isoliert mit Read-Only Tools
4. Main Agent erh√§lt Report zur√ºck
5. Main Agent zeigt Zusammenfassung

**Warum Subagent?**
- ‚úÖ **Tool-Isolation:** Nur Read, Grep, Glob (kein Write!)
- ‚úÖ **Security:** Kann nichts kaputt machen
- ‚úÖ **Separation of Concerns:** Fokussiert nur auf Security
- ‚úÖ **Parallel m√∂glich:** Mehrere Subagents f√ºr verschiedene Scan-Typen

---

### Praxisbeispiel 2: Failing Tests parallel fixen

**Szenario:** 10 Tests failen nach Refactoring. Du willst sie parallel fixen.

**L√∂sung: Subagent per Test**

```markdown
---
name: test-fixer
description: Fix failing test by analyzing code and test expectations
tools: ["Read", "Write", "Bash", "Grep"]
---

# Test Fixer Subagent

Fix a single failing test.

## Input

Receives from Main Agent:
- Test file path
- Test name
- Failure message

## Process

1. **Read test file**
   - Understand what test expects
   - Identify assertion that failed

2. **Read implementation**
   - Find function/component being tested
   - Analyze current behavior

3. **Identify root cause**
   - Compare expected vs. actual
   - Find bug in implementation or test

4. **Fix**
   - If bug in code: Fix implementation
   - If bug in test: Update test expectations
   - Preserve test coverage

5. **Verify**
   - Run fixed test
   - Ensure it passes
   - Ensure no other tests broke

## Output

```json
{
  "test": "UserService.createUser",
  "status": "fixed",
  "root_cause": "Missing email validation",
  "changes": [
    "src/services/UserService.ts:42 - Added email validation"
  ],
  "verification": "Test now passes"
}
```
```

**Main Agent Orchestrierung:**

```markdown
# Main Agent Logic

1. Run test suite: `npm test`
2. Parse failures (e.g., 10 failing tests)
3. For each failing test:
   - Start Test Fixer Subagent
   - Pass test info (file, name, error)
4. All Subagents run in parallel
5. Collect results
6. Aggregate fixes
7. Final verification: `npm test`
```

**Workflow:**
1. Main Agent: Runs tests ‚Üí 10 failures
2. Main Agent: Startet 10 Test Fixer Subagents parallel
3. Jeder Subagent:
   - Analysiert seinen Test
   - Findet Root Cause
   - Fixt Code
   - Verifiziert Fix
4. Main Agent: Sammelt alle Fixes
5. Main Agent: Final Test Run ‚Üí Alle gr√ºn ‚úÖ

**Warum Subagent?**
- ‚úÖ **Parallelisierung:** 10 Tests gleichzeitig fixen (10x schneller!)
- ‚úÖ **Isolation:** Jeder Subagent fokussiert auf einen Test
- ‚úÖ **Skalierbar:** Funktioniert f√ºr 10 oder 100 Tests

**Zeitersparnis:**
- Sequenziell: 10 Tests √ó 5 Min = 50 Minuten
- Parallel: ~5-7 Minuten (alle gleichzeitig)

---

### Praxisbeispiel 3: Parallele Git Work Trees

**Szenario:** 3 Features gleichzeitig in separaten Worktrees entwickeln.

**L√∂sung: Subagent pro Feature**

```markdown
---
name: feature-developer
description: Develop feature in isolated git worktree
tools: ["Read", "Write", "Edit", "Bash", "Grep", "Glob"]
---

# Feature Developer Subagent

Develop a complete feature in isolated worktree.

## Input

Receives from Main Agent:
- Feature name
- Feature description
- Acceptance criteria

## Process

1. **Setup** (done by Main Agent)
   - Worktree created: `../worktree-{feature-name}`
   - Branch created: `feature/{feature-name}`

2. **Implementation**
   - Read @CLAUDE.md for architecture
   - Implement feature according to criteria
   - Follow coding standards
   - Write tests

3. **Verification**
   - Run tests: `npm test`
   - Run linting: `npm run lint`
   - Build: `npm run build`

4. **Commit**
   - Generate conventional commit message
   - Commit changes

## Output

```json
{
  "feature": "user-authentication",
  "status": "completed",
  "worktree": "../worktree-user-authentication",
  "branch": "feature/user-authentication",
  "files_changed": 12,
  "tests_added": 8,
  "ready_for_review": true
}
```
```

**Main Agent Orchestrierung:**

```markdown
# Main Agent Logic

## Step 1: Setup Worktrees
For each feature:
- `/create-worktree {feature-name}`

## Step 2: Start Feature Developer Subagents
Feature 1: "User Authentication"
‚Üí Subagent in worktree-user-authentication

Feature 2: "Dashboard Redesign"
‚Üí Subagent in worktree-dashboard-redesign

Feature 3: "Payment Integration"
‚Üí Subagent in worktree-payment-integration

All run in parallel!

## Step 3: Monitor Progress
- Check Subagent outputs
- Report progress to user

## Step 4: Review & Merge
When all Subagents done:
- Review each feature
- Merge back to main
- Clean up worktrees
```

**Workflow:**
1. User: "Implement these 3 features parallel"
2. Main Agent: Erstellt 3 Worktrees
3. Main Agent: Startet 3 Feature Developer Subagents
4. Alle 3 Subagents entwickeln parallel in isolierten Worktrees
5. Main Agent: Sammelt Results
6. Main Agent: Reviewed und merged alle Features

**Warum Subagent?**
- ‚úÖ **Parallelisierung:** 3 Features gleichzeitig
- ‚úÖ **Isolation:** Jedes Feature in eigenem Worktree + Branch
- ‚úÖ **Context-Isolation:** Keine Konflikte zwischen Features

**Zeitersparnis:**
- Sequenziell: 3 Features √ó 30 Min = 90 Minuten
- Parallel: ~30-35 Minuten (alle gleichzeitig)

---

### Praxisbeispiel 4: Multi-Repository Security-Scan

**Szenario:** Dein Team hat 20 Repositories die alle gescannt werden sollen.

**L√∂sung: Subagent pro Repository**

```markdown
---
name: repo-security-scanner
description: Scan single repository for security issues
tools: ["Read", "Grep", "Glob", "Bash"]
model: claude-haiku-4.5  # Schneller f√ºr Batch-Processing
---

# Repository Security Scanner

Scan a single repository for security vulnerabilities.

## Input
- Repository path
- Repository name

## Scan Steps

1. **Clone/Update Repo** (if needed)
2. **Run Security Checks:**
   - Hardcoded secrets
   - Dependency vulnerabilities
   - Code patterns (SQL injection, XSS)
3. **Generate Report**

## Output

```json
{
  "repo": "api-backend",
  "status": "scanned",
  "issues": {
    "critical": 1,
    "high": 3,
    "medium": 5
  },
  "details": [...]
}
```
```

**Main Agent Orchestrierung:**

```markdown
# Batch Scan 20 Repositories

1. List all repos
2. For each repo: Start repo-security-scanner Subagent
3. All 20 Subagents run in parallel
4. Collect reports
5. Aggregate results
6. Generate dashboard
```

**Workflow:**
1. Main Agent: Liest Liste von 20 Repos
2. Main Agent: Startet 20 Subagents parallel
3. Jeder Subagent scannt ein Repo
4. Main Agent: Sammelt alle Reports
5. Main Agent: Aggregiert zu Dashboard

**Warum Subagent?**
- ‚úÖ **Massive Parallelisierung:** 20 Repos gleichzeitig
- ‚úÖ **Isolation:** Kein Cross-Repo-Context
- ‚úÖ **Skalierbar:** Funktioniert f√ºr 20 oder 200 Repos

**Zeitersparnis:**
- Sequenziell: 20 Repos √ó 10 Min = 200 Minuten (3+ Stunden!)
- Parallel: ~10-15 Minuten

---

## MCP SERVER - Externe Integrationen

### Wann nutzen

‚úÖ **Daten von externen Systemen** (Jira, Salesforce, Slack)
‚úÖ **Datenbank-Zugriff** (PostgreSQL, MySQL, MongoDB)
‚úÖ **Cloud Storage** (Google Drive, Box, Dropbox)
‚úÖ **APIs mit Authentication** (GitHub, GitLab, Linear)
‚úÖ **Propriet√§re Systeme** (internes CRM, ERP)

### Wann NICHT nutzen

‚ùå **F√ºr lokale Dateien** (nutze Built-in Tools: Read, Write)
‚ùå **Wenn kein externes System involviert ist**
‚ùå **Bei zu vielen MCP Servern** (Context-Window-Explosion!)
‚ùå **F√ºr einfache HTTP Requests** (nutze Bash + curl)

---

### Praxisbeispiel 1: Jira-Integration

**Szenario:** Du willst dass Claude Issues aus Jira lesen und aktualisieren kann.

**L√∂sung: MCP Server**

**Konfiguration:**

```json
{
  "mcpServers": {
    "jira": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-jira"],
      "env": {
        "JIRA_URL": "https://yourcompany.atlassian.net",
        "JIRA_TOKEN": "your-api-token",
        "JIRA_USER": "your-email@company.com"
      }
    }
  }
}
```

**Use Cases:**

```markdown
# 1. Issue Lookup
User: "Zeig mir alle offenen Bugs in Sprint 23"
‚Üí Claude nutzt Jira MCP automatisch
‚Üí Query: project = PROJ AND sprint = 23 AND type = Bug AND status != Closed
‚Üí Zeigt Liste mit Bugs

# 2. Issue Creation
User: "Erstelle Bug-Ticket f√ºr Login-Problem"
‚Üí Claude erstellt Jira Issue:
  - Type: Bug
  - Summary: Login fails with SSO
  - Description: [Details from conversation]
  - Assignee: [from team roster]

# 3. Status Update
User: "Setze Issue PROJ-123 auf Done"
‚Üí Claude updated Jira Issue
‚Üí Adds transition comment
‚Üí Best√§tigt Update

# 4. Sprint Planning
User: "Welche Issues sind f√ºr n√§chsten Sprint geplant?"
‚Üí Query: sprint = 24 AND status = "To Do"
‚Üí Zeigt Liste mit Story Points
```

**Warum MCP Server?**
- ‚úÖ **Externe Integration:** Jira ist externes System
- ‚úÖ **Authentication:** API Token n√∂tig
- ‚úÖ **Native MCP Server verf√ºgbar**
- ‚úÖ **Real-time Daten:** Immer aktuell

---

### Praxisbeispiel 2: Google Drive + QBR Skill

**Szenario:** Erstelle Quarterly Business Review (QBR) basierend auf Template in Google Drive und Sales-Daten aus Salesforce.

**L√∂sung: Skill + 2 MCP Server**

**Konfiguration:**

```json
{
  "mcpServers": {
    "google-drive": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-google-drive"],
      "env": {
        "GOOGLE_CLIENT_ID": "...",
        "GOOGLE_CLIENT_SECRET": "..."
      }
    },
    "salesforce": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-salesforce"],
      "env": {
        "SALESFORCE_USERNAME": "...",
        "SALESFORCE_PASSWORD": "...",
        "SALESFORCE_TOKEN": "..."
      }
    }
  }
}
```

**Skill:**

```markdown
---
name: QBR Creator
description: Create Quarterly Business Review presentation from template. Use when user requests QBR, quarterly review, or business review presentation.
---

# QBR Creator Skill

Create comprehensive QBR presentation using template and live data.

## Process

1. **Load Template**
   - Google Drive MCP: Fetch "QBR_Template_2024.pptx"
   - Parse template structure

2. **Gather Data**
   - Salesforce MCP: Query sales data for quarter
     - Pipeline value
     - Closed deals
     - Win rate
     - Top customers
   - Salesforce MCP: Query customer health scores

3. **Generate Content**
   - Executive Summary slide
   - Sales Performance slide (charts from Salesforce data)
   - Customer Highlights slide
   - Challenges & Learnings slide
   - Next Quarter Goals slide

4. **Create Presentation**
   - Fill template with data
   - Generate charts
   - Format consistently

5. **Save**
   - Google Drive MCP: Save as "QBR_Q4_2025.pptx"
   - Share link with stakeholders

## Example Usage

User: "Erstelle Q4 QBR"
‚Üí Skill aktiviert
‚Üí L√§dt Template aus Google Drive
‚Üí Holt Sales-Daten aus Salesforce
‚Üí Generiert Pr√§sentation
‚Üí Speichert in Google Drive
```

**Workflow:**
1. User: "Erstelle Q4 QBR"
2. QBR Skill aktiviert (Keywords: "QBR", "quarterly review")
3. Google Drive MCP: L√§dt Template
4. Salesforce MCP: Holt Sales-Daten f√ºr Q4
5. Skill: Generiert Slides mit Daten + Charts
6. Google Drive MCP: Speichert neue PPTX
7. User erh√§lt Link

**Warum diese Komposition?**
- ‚úÖ **Skill:** Orchestriert den Prozess (WIE)
- ‚úÖ **Google Drive MCP:** Template laden + Speichern (WO)
- ‚úÖ **Salesforce MCP:** Live Sales-Daten (DATEN)

**Ohne MCP w√ºrde es nicht gehen:**
- ‚ùå Keine Template-Integration
- ‚ùå Keine aktuellen Sales-Daten
- ‚ùå Manuelle Arbeit statt Automatisierung

---

### Praxisbeispiel 3: PostgreSQL Datenbank-Analysen

**Szenario:** Datenanalysen direkt aus der Produktions-DB.

**L√∂sung: MCP Server (Read-Only!)**

**Konfiguration:**

```json
{
  "mcpServers": {
    "postgres": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-postgres"],
      "env": {
        "POSTGRES_CONNECTION_STRING": "postgresql://readonly_user:password@prod-db.company.com:5432/main_db"
      }
    }
  }
}
```

**‚ö†Ô∏è WICHTIG: Read-Only User!**

Erstelle DB-User mit nur Lese-Rechten:

```sql
CREATE USER readonly_user WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE main_db TO readonly_user;
GRANT USAGE ON SCHEMA public TO readonly_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user;
```

**Use Cases:**

```markdown
# 1. Ad-hoc Queries
User: "Wie viele User haben sich letzte Woche registriert?"
‚Üí Claude: SELECT COUNT(*) FROM users WHERE created_at > NOW() - INTERVAL '7 days'
‚Üí Ergebnis: 234 User

# 2. Performance Analysis
User: "Welche Queries laufen am l√§ngsten?"
‚Üí Claude: SELECT query, mean_exec_time FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10
‚Üí Zeigt Top 10 langsame Queries

# 3. Data Trends
User: "Zeig mir User-Wachstum pro Monat"
‚Üí Claude: SELECT DATE_TRUNC('month', created_at) as month, COUNT(*)
          FROM users
          GROUP BY month
          ORDER BY month
‚Üí Generiert Chart

# 4. Complex Joins
User: "Welche Kunden haben im letzten Quartal √ºber $10k ausgegeben?"
‚Üí Claude:
  SELECT c.name, SUM(o.total) as revenue
  FROM customers c
  JOIN orders o ON c.id = o.customer_id
  WHERE o.created_at > NOW() - INTERVAL '3 months'
  GROUP BY c.id, c.name
  HAVING SUM(o.total) > 10000
  ORDER BY revenue DESC
‚Üí Liste mit Top Customers
```

**Warum MCP Server?**
- ‚úÖ **Externe Datenbank**
- ‚úÖ **SQL Queries** (nicht √ºber Built-in Tools m√∂glich)
- ‚úÖ **Authentication** (Connection String)
- ‚úÖ **Live Data** (immer aktuell)

**Security Best Practice:**
- üîí **Read-Only User:** Kann nichts kaputt machen
- üîí **No DROP/DELETE:** Nur SELECT erlaubt
- üîí **Production Safety:** Zero Risk

---

### Praxisbeispiel 4: Slack-Benachrichtigungen

**Szenario:** Automatische Slack-Benachrichtigungen bei Deployments oder Errors.

**L√∂sung: MCP Server + Hook**

**Konfiguration:**

```json
{
  "mcpServers": {
    "slack": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-slack"],
      "env": {
        "SLACK_BOT_TOKEN": "xoxb-...",
        "SLACK_TEAM_ID": "T..."
      }
    }
  },
  "hooks": {
    "PostToolUse": {
      "Bash(*deploy*)": "node .claude/hooks/notify-deployment.js"
    }
  }
}
```

**Hook Script:**

```javascript
// .claude/hooks/notify-deployment.js
const { sendSlackMessage } = require('./slack-utils');

// Wird nach jedem deployment-bezogenen Bash Command ausgef√ºhrt
async function notifyDeployment() {
  await sendSlackMessage({
    channel: '#deployments',
    text: `üöÄ Deployment completed by Claude`,
    blocks: [
      {
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: '*Deployment Summary*\n‚Ä¢ Status: ‚úÖ Success\n‚Ä¢ Time: 2 minutes\n‚Ä¢ Environment: Production'
        }
      }
    ]
  });
}

notifyDeployment();
```

**Use Cases:**

```markdown
# 1. Deployment Notification
User: "/deploy"
‚Üí Deployment l√§uft
‚Üí Hook triggered nach Bash Command
‚Üí Slack Nachricht in #deployments

# 2. Error Alerts
User: "Run tests"
‚Üí Tests failen
‚Üí Hook detected failure
‚Üí Slack Nachricht in #alerts mit Error Details

# 3. Daily Standup
User: "Post standup update"
‚Üí Claude sammelt git commits vom Tag
‚Üí Slack MCP: Postet in #standup Channel
```

**Warum diese Komposition?**
- ‚úÖ **MCP Server:** Slack-Integration (API Access)
- ‚úÖ **Hook:** Garantierte Automatisierung nach Events
- ‚úÖ **Kombination:** Hook nutzt MCP f√ºr Slack-Posting

---

## HOOKS - Event-Driven Automation

### Wann nutzen

‚úÖ **Garantierte Automatisierung** (nicht LLM-abh√§ngig!)
‚úÖ **Code-Qualit√§tssicherung** (Formatting, Linting)
‚úÖ **Security-Enforcement** (Production Writes blockieren)
‚úÖ **PreToolUse:** Einzige M√∂glichkeit Tools zu blockieren!
‚úÖ **PostToolUse:** Automatisches Post-Processing

### Wann NICHT nutzen

‚ùå **F√ºr komplexe Logik** (Hooks sind Shell-Commands)
‚ùå **Wenn LLM-Entscheidung gew√ºnscht** (nutze Skill)
‚ùå **F√ºr asynchrone Ops** (Hooks blockieren Workflow)

---

### Praxisbeispiel 1: Auto-Formatting

**Szenario:** Automatisches Formatting nach jedem Write.

**L√∂sung: PostToolUse Hook**

**Konfiguration:**

```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/*.py)": "black $FILE && ruff check $FILE",
      "Write(**/*.ts)": "prettier --write $FILE && eslint --fix $FILE",
      "Write(**/*.tsx)": "prettier --write $FILE && eslint --fix $FILE",
      "Write(**/*.go)": "gofmt -w $FILE",
      "Write(**/*.rs)": "rustfmt $FILE"
    }
  }
}
```

**Workflow:**
1. Claude: `Write src/components/Button.tsx`
2. File geschrieben
3. Hook triggered automatisch:
   - `prettier --write Button.tsx` ‚Üí Formatiert
   - `eslint --fix Button.tsx` ‚Üí Fixt Lint-Errors
4. File ist jetzt formatiert + gelintet

**Warum Hook?**
- ‚úÖ **Garantiert:** Wird IMMER ausgef√ºhrt (nicht LLM-abh√§ngig)
- ‚úÖ **Automatisch:** Kein manueller Schritt
- ‚úÖ **Zero Overhead:** Entwickler muss nicht dran denken
- ‚úÖ **Team-Standard:** Jeder Code ist konsistent formatiert

---

### Praxisbeispiel 2: Security - Production Writes blockieren

**Szenario:** Verhindern dass Claude direkt in Production schreibt.

**L√∂sung: PreToolUse Hook (blockiert Tool!)**

**Konfiguration:**

```json
{
  "hooks": {
    "PreToolUse": {
      "Write(**/production/**)": "echo '‚ùå ERROR: Direct writes to production/ are forbidden!' && exit 1",
      "Write(**/prod/**)": "echo '‚ùå ERROR: Direct writes to prod/ are forbidden!' && exit 1",
      "Bash(**/production/**)": "echo '‚ö†Ô∏è  WARNING: Bash commands in production/ require manual approval' && exit 1"
    }
  }
}
```

**Workflow:**

**Blockierter Fall:**
1. Claude: `Write production/config.json`
2. PreToolUse Hook triggered
3. Script: `exit 1` ‚Üí Blockiert Tool!
4. Claude erh√§lt Error: "Direct writes to production/ are forbidden!"
5. Write wird NICHT ausgef√ºhrt ‚ùå

**Erlaubter Fall:**
1. Claude: `Write src/components/Button.tsx`
2. Kein Hook matched ‚Üí Write l√§uft normal ‚úÖ

**Warum Hook (PreToolUse)?**
- ‚úÖ **Security:** Verhindert versehentliche Production Changes
- ‚úÖ **PreToolUse:** Einzige M√∂glichkeit Tools zu blockieren!
- ‚úÖ **Garantiert:** Funktioniert auch wenn Claude "falsch denkt"
- ‚úÖ **Zero Risk:** Production ist gesch√ºtzt

---

### Praxisbeispiel 3: Test-Enforcement

**Szenario:** Jede neue Funktion muss getestet sein.

**L√∂sung: PostToolUse Hook mit Validation**

**Konfiguration:**

```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/src/**/*.ts)": "node .claude/hooks/enforce-tests.js $FILE"
    }
  }
}
```

**Hook Script:**

```javascript
// .claude/hooks/enforce-tests.js
const fs = require('fs');
const path = require('path');

const filePath = process.argv[2]; // $FILE von Hook
const fileContent = fs.readFileSync(filePath, 'utf-8');

// Check: Hat File neue Funktionen?
const hasNewFunctions = /export (function|const \w+ =)/.test(fileContent);

if (hasNewFunctions) {
  // Check: Existiert Test-File?
  const testPath = filePath.replace(/\.ts$/, '.test.ts');

  if (!fs.existsSync(testPath)) {
    console.error(`‚ùå ERROR: ${path.basename(filePath)} has new functions but no test file!`);
    console.error(`Expected test file: ${testPath}`);
    process.exit(1); // Block!
  }

  // Check: Hat Test-File Tests f√ºr neue Funktionen?
  const testContent = fs.readFileSync(testPath, 'utf-8');
  // Simple check: Hat mindestens 1 test() oder it() call
  if (!/test\(|it\(/.test(testContent)) {
    console.error(`‚ùå ERROR: ${testPath} exists but has no tests!`);
    process.exit(1);
  }

  console.log(`‚úÖ Tests found for ${path.basename(filePath)}`);
}
```

**Workflow:**

**Mit Tests:**
1. Claude: `Write src/utils/formatDate.ts` (neue Funktion)
2. PostToolUse Hook triggered
3. Script pr√ºft: formatDate.test.ts existiert? ‚úÖ
4. Script pr√ºft: Tests vorhanden? ‚úÖ
5. ‚úÖ Success

**Ohne Tests:**
1. Claude: `Write src/utils/formatDate.ts` (neue Funktion)
2. PostToolUse Hook triggered
3. Script pr√ºft: formatDate.test.ts existiert? ‚ùå
4. Script: `exit 1` ‚Üí Fehler!
5. Claude erh√§lt Error: "formatDate.ts has new functions but no test file!"
6. Claude muss Tests nachliefern

**Warum Hook?**
- ‚úÖ **Garantiert:** Tests werden erzwungen
- ‚úÖ **Team-Standard:** 100% Test-Coverage
- ‚úÖ **Automatisch:** Kein manuelles Review n√∂tig

---

### Praxisbeispiel 4: Git Commit Hooks

**Szenario:** Conventional Commit Messages erzwingen.

**L√∂sung: PreToolUse Hook f√ºr Git**

**Konfiguration:**

```json
{
  "hooks": {
    "PreToolUse": {
      "Bash(git commit*)": "node .claude/hooks/validate-commit-msg.js \"$COMMAND\""
    }
  }
}
```

**Hook Script:**

```javascript
// .claude/hooks/validate-commit-msg.js
const command = process.argv[2]; // "git commit -m 'message'"

// Extract commit message from command
const match = command.match(/git commit.*-m ["'](.+)["']/);
if (!match) {
  console.error('‚ùå Could not parse commit message');
  process.exit(1);
}

const commitMsg = match[1];

// Conventional Commit Format: type(scope): subject
const conventionalPattern = /^(feat|fix|docs|style|refactor|test|chore)(\(.+\))?: .{3,50}$/;

if (!conventionalPattern.test(commitMsg)) {
  console.error('‚ùå ERROR: Commit message does not follow Conventional Commits!');
  console.error('');
  console.error('Format: <type>(<scope>): <subject>');
  console.error('');
  console.error('Valid types: feat, fix, docs, style, refactor, test, chore');
  console.error('Example: feat(auth): add OAuth2 login');
  console.error('');
  console.error(`Your message: "${commitMsg}"`);
  process.exit(1);
}

console.log('‚úÖ Commit message valid');
```

**Workflow:**

**Valid Commit:**
1. Claude: `git commit -m "feat(auth): add OAuth2 login"`
2. PreToolUse Hook triggered
3. Script validiert: Conventional Format? ‚úÖ
4. Commit l√§uft durch

**Invalid Commit:**
1. Claude: `git commit -m "added login feature"`
2. PreToolUse Hook triggered
3. Script validiert: Conventional Format? ‚ùå
4. Script: `exit 1` ‚Üí Blockiert!
5. Claude erh√§lt Error mit Format-Hilfe
6. Claude muss Commit Message korrigieren

**Warum Hook?**
- ‚úÖ **Garantiert:** Alle Commits folgen Standard
- ‚úÖ **PreToolUse:** Verhindert invalide Commits
- ‚úÖ **Team-Standard:** Saubere Git History

---

## üîÑ KOMPOSITIONSHIERARCHIE

Verstehe welche Tools andere Tools aufrufen k√∂nnen:

### Hierarchie-Diagramm

```mermaid
graph TB
    subgraph "H√∂chste Ebene - Maximale Kompositionsf√§higkeit"
        A[Skills]
        B[Slash Commands]
    end

    subgraph "Mittlere Ebene"
        C[MCP Server]
        D[Subagenten]
    end

    subgraph "Niedrigste Ebene"
        E[Hooks]
        F[Built-in Tools]
    end

    A -->|kann nutzen| B
    A -->|kann nutzen| C
    A -->|kann nutzen| D
    A -->|kann nutzen| F

    B -->|kann aufrufen| A
    B -->|kann nutzen| C
    B -->|kann nutzen| D
    B -->|kann nutzen| F

    D -->|kann nutzen| A
    D -->|kann nutzen| B
    D -->|kann nutzen| C
    D -->|kann nutzen| F
    D -.->|NICHT m√∂glich| D

    C -->|kann nutzen| F
    C -.->|sollte nicht| A

    E -->|kann aufrufen| F
    E -.->|kein LLM-Zugriff| A
    E -.->|kein LLM-Zugriff| B

    style A fill:#99ff99
    style B fill:#ffff99
    style C fill:#ff9999
    style D fill:#99ccff
    style E fill:#ff99ff
    style F fill:#cccccc
```

### Detaillierte Regeln

#### 1. Skills (H√∂chste Ebene)

**K√∂nnen nutzen:**
- ‚úÖ Andere Skills aufrufen
- ‚úÖ Slash Commands aufrufen (via SlashCommand Tool)
- ‚úÖ Subagenten starten
- ‚úÖ MCP Server nutzen
- ‚úÖ Built-in Tools nutzen

**Beispiel: Git Worktree Manager Skill**

```markdown
# Skill orchestriert Commands
- `/create-worktree` (Slash Command)
- `/list-worktrees` (Slash Command)
- `/merge-worktree` (Slash Command)
```

**Komplexes Beispiel: QBR Skill**

```markdown
# Skill nutzt alles:
1. Google Drive MCP (Template laden)
2. Salesforce MCP (Sales-Daten)
3. Andere Skills (Chart Generator Skill)
4. Built-in Tools (Write f√ºr Output)
```

---

#### 2. Slash Commands (H√∂chste Ebene)

**K√∂nnen nutzen:**
- ‚úÖ Skills aktivieren (automatisch via Description)
- ‚úÖ Andere Slash Commands aufrufen
- ‚úÖ Subagenten starten
- ‚úÖ MCP Server nutzen
- ‚úÖ Built-in Tools nutzen

**Beispiel: Deployment Command**

```markdown
# /deploy Command orchestriert:
1. /build (anderer Command)
2. /test (anderer Command)
3. Security Scanner Skill (aktiviert automatisch)
4. Slack MCP (Notification)
```

**Wichtig:** Commands sind Primitives - oft die Building Blocks f√ºr Skills!

---

#### 3. Subagenten (Mittlere Ebene)

**K√∂nnen nutzen:**
- ‚úÖ Skills nutzen (haben Zugriff)
- ‚úÖ Slash Commands aufrufen
- ‚úÖ MCP Server nutzen
- ‚úÖ Built-in Tools nutzen (eingeschr√§nkt via `tools` config)

**NICHT m√∂glich:**
- ‚ùå Andere Subagenten aufrufen (technische Limitation!)

**Beispiel: Feature Developer Subagent**

```markdown
---
tools: ["Read", "Write", "Bash"]
---

# Kann nutzen:
- Read/Write/Bash (whitelisted)
- Skills (automatisch verf√ºgbar)
- /create-component (Slash Command)
- MCP Server

# Kann NICHT:
- Andere Subagenten starten
- Tools au√üerhalb Whitelist (z.B. kein Grep wenn nicht in tools)
```

---

#### 4. MCP Server (Mittlere Ebene)

**K√∂nnen nutzen:**
- ‚úÖ Built-in Tools (theoretisch, aber selten n√∂tig)

**Sollten NICHT:**
- ‚ö†Ô∏è Skills aufrufen (niedrigere Ebene der Abstraktion)
- ‚ö†Ô∏è Slash Commands aufrufen

**Wichtig:** MCP Server sind **Datenquellen**, keine Orchestratoren!

**Richtig:**
```markdown
Skill ‚Üí nutzt ‚Üí MCP Server (Daten holen)
```

**Falsch:**
```markdown
MCP Server ‚Üí ruft ‚Üí Skill auf
```

---

#### 5. Hooks (Niedrigste Ebene)

**K√∂nnen nutzen:**
- ‚úÖ Shell-Commands ausf√ºhren
- ‚úÖ Scripts aufrufen
- ‚ö†Ô∏è Built-in Tools indirekt (via Claude Response)

**NICHT m√∂glich:**
- ‚ùå Skills aufrufen (keine LLM-Logik)
- ‚ùå Slash Commands aufrufen (keine LLM-Logik)
- ‚ùå MCP Server nutzen (keine LLM-Logik)

**Beispiel:**

```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/*.ts)": "prettier --write $FILE"  // Shell Command OK
    }
  }
}
```

**Wichtig:** Hooks sind **Shell-Scripts**, keine LLM-gesteuerte Logik!

---

### Praktische Kompositions-Beispiele

#### Beispiel 1: Multi-Layer QBR Pipeline

```markdown
Layer 1: Slash Command "/create-qbr Q4"
  ‚Üì
Layer 2: QBR Creator Skill (aktiviert automatisch)
  ‚Üì
Layer 3a: Google Drive MCP (Template laden)
Layer 3b: Salesforce MCP (Sales-Daten)
Layer 3c: Chart Generator Skill (Visualisierungen)
  ‚Üì
Layer 4: Built-in Tools (Write f√ºr PPTX)
  ‚Üì
Layer 5: PostToolUse Hook (Auto-Format)
```

**Alle Ebenen zusammen!**

---

#### Beispiel 2: Parallel Feature Development

```markdown
Layer 1: Slash Command "/parallel-features feature-a feature-b"
  ‚Üì
Layer 2: Orchestrator Skill
  ‚Üì
  ‚îú‚îÄ Subagent A (feature-a)
  ‚îÇ   ‚Üì
  ‚îÇ   ‚îú‚îÄ Component Creator Skill
  ‚îÇ   ‚îú‚îÄ /create-component (Command)
  ‚îÇ   ‚îî‚îÄ GitHub MCP (Create PR)
  ‚îÇ
  ‚îî‚îÄ Subagent B (feature-b)
      ‚Üì
      ‚îú‚îÄ API Generator Skill
      ‚îú‚îÄ /create-endpoint (Command)
      ‚îî‚îÄ Jira MCP (Update Issue)
```

**Parallel Execution mit voller Komposition!**

---

### Context-Window-Impact Visualisierung

```mermaid
graph LR
    subgraph "Context-Effizient ‚úÖ"
        A[Skills<br/>Progressive Disclosure]
        B[Slash Commands<br/>On-Demand Load]
        C[Subagenten<br/>Isolated Context]
    end

    subgraph "Context-Intensiv ‚ö†Ô∏è"
        D[MCP Server<br/>All Tools in Context]
    end

    subgraph "Kein Context-Impact"
        E[Hooks<br/>Shell Scripts]
    end

    A -->|Stufe 1: Metadata| F[Small Context]
    A -->|Stufe 2: Instructions| G[Medium Context]
    A -->|Stufe 3: Resources| H[Large Context]

    B -->|Nur wenn aufgerufen| F

    C -->|Eigener Context| I[Isolated]

    D -->|Alle Tools sofort| J[Large Context!]

    style A fill:#99ff99
    style B fill:#ffff99
    style C fill:#99ccff
    style D fill:#ff9999
    style E fill:#ff99ff
```

---

## üöÄ "PROMPT FIRST" WORKFLOW

### Die goldene Regel

> **Fang immer einfach an. Skaliere nur wenn n√∂tig.**

Zu viele Entwickler machen den Fehler direkt mit komplexen Tools zu starten. Das Ergebnis:
- ‚ùå Overengineering
- ‚ùå Maintenance-Overhead
- ‚ùå Schwer zu debuggen
- ‚ùå Context-Window-Pollution

**Die richtige Reihenfolge:**
1. Direkter Prompt
2. Slash Command (wenn wiederholbar)
3. Skill ODER Subagent (wenn komplexer)
4. + MCP Server (wenn externe Daten)

---

### Migrations-Stufen im Detail

#### Stufe 1: Direkter Prompt

**Wann ausreichend:**
- ‚úÖ Einmalige Aufgabe
- ‚úÖ Exploratives Ausprobieren
- ‚úÖ Unklar ob wiederholbar

**Beispiel:**

```
User: "Erstelle mir eine git commit message f√ºr die staged changes"
```

Claude macht es ‚Üí Fertig!

**Wann zur n√§chsten Stufe?**
‚Üí Wenn du merkst: "Das mache ich √∂fter als 3x"

---

#### Stufe 2: Slash Command

**Wann sinnvoll:**
- ‚úÖ Task wird wiederholt (>3x)
- ‚úÖ Willst manuelle Kontrolle behalten
- ‚úÖ Klare Schrittfolge

**Migration:**

Direkter Prompt:
```
"Erstelle conventional commit message f√ºr staged changes"
```

Wird zu Slash Command:
```markdown
---
name: commit-msg
description: Generate conventional commit message
---

# Commit Message Generator

1. Run git diff --staged
2. Analyze changes
3. Generate conventional commit format
```

**Vorteile:**
- ‚úÖ Wiederverwendbar via `/commit-msg`
- ‚úÖ Konsistente Qualit√§t
- ‚úÖ Team kann gleichen Command nutzen

**Wann zur n√§chsten Stufe?**
‚Üí Wenn du willst dass:
- Claude automatisch erkennt wann relevant ‚Üí **Skill**
- Task parallel laufen soll ‚Üí **Subagent**

---

#### Stufe 3a: Skill (Automatische Aktivierung)

**Wann sinnvoll:**
- ‚úÖ Claude soll automatisch erkennen wann relevant
- ‚úÖ Wiederkehrendes Muster
- ‚úÖ Mehrere Schritte involviert
- ‚úÖ Team-Standard

**Migration:**

Slash Command:
```markdown
---
name: commit-msg
---
Generate commit message
```

Wird zu Skill:
```markdown
---
name: Commit Message Generator
description: Generate commit messages following team conventions. Use after code changes before committing.
---

# Commit Message Generator

When user mentions committing or has staged changes:

1. Run git diff --staged
2. Generate conventional commit message
3. Follow team standards from @CLAUDE.md
```

**Vorteile:**
- ‚úÖ Automatische Aktivierung (kein `/` n√∂tig)
- ‚úÖ Claude erkennt selbst wann relevant
- ‚úÖ Nat√ºrlichere Interaction

**Beispiel:**

```
User: "Ich hab die Auth fertig, k√∂nnen wir committen?"
‚Üí Skill aktiviert automatisch (Keywords: "committen")
‚Üí Generiert Message
‚Üí Claude fragt: "Soll ich damit committen?"
```

**Nachteil:**
- ‚ö†Ô∏è Weniger explizite Kontrolle
- ‚ö†Ô∏è Skill-Overhead (Progressive Disclosure)

---

#### Stufe 3b: Subagent (Parallelisierung)

**Wann sinnvoll:**
- ‚úÖ Task muss parallel laufen
- ‚úÖ Tool-Isolation gew√ºnscht
- ‚úÖ Batch-Processing

**Migration:**

Slash Command:
```markdown
---
name: fix-test
---
Fix single failing test
```

Wird zu Subagent:
```markdown
---
name: test-fixer
tools: ["Read", "Write", "Bash"]
---

Fix a single failing test.

Input: Test name, file, error
Output: Fixed test + verification
```

**Main Agent orchestriert:**

```markdown
# Main Agent
1. Run all tests ‚Üí 10 failures
2. For each failure: Start test-fixer Subagent
3. All run in parallel
4. Collect results
```

**Vorteile:**
- ‚úÖ Massive Parallelisierung
- ‚úÖ Tool-Isolation (Security)
- ‚úÖ Schneller als sequenziell

**Nachteil:**
- ‚ö†Ô∏è Context geht verloren
- ‚ö†Ô∏è Komplexer zu orchestrieren

---

#### Stufe 4: + MCP Server (Externe Daten)

**Wann sinnvoll:**
- ‚úÖ Externe Systeme involviert
- ‚úÖ API-Zugriff n√∂tig
- ‚úÖ Real-time Daten

**Migration:**

Skill:
```markdown
---
name: Commit Message Generator
---
Generate commit message
```

Wird zu Skill + MCP:
```markdown
---
name: Commit Message Generator
---

# Mit Jira-Integration

1. Generate commit message
2. Jira MCP: Get Issue details (if mentioned)
3. Add Issue ID to commit footer
4. Add Issue title to commit body

Example:
"feat(auth): add OAuth2 login

Implements OAuth2 for Google and GitHub.

Issue: PROJ-123 - Add OAuth login options"
```

**Vorteile:**
- ‚úÖ Kontext aus Jira
- ‚úÖ Automatische Issue-Verlinkung
- ‚úÖ Vollst√§ndigere Commit Messages

---

### Migrations-Entscheidungsbaum

```mermaid
graph TD
    A[Direkter Prompt] -->|Wiederholbar?| B{Mehr als 3x?}
    B -->|Ja| C[Slash Command]
    B -->|Nein| A

    C -->|Automatisch?| D{Claude soll<br/>erkennen wann?}
    C -->|Parallel?| E{Muss parallel<br/>laufen?}

    D -->|Ja| F[Skill]
    D -->|Nein| C

    E -->|Ja| G[Subagent]
    E -->|Nein| C

    F -->|Externe Daten?| H{Externe<br/>Systeme?}
    H -->|Ja| I[Skill + MCP]
    H -->|Nein| F

    G -->|Externe Daten?| J{Externe<br/>Systeme?}
    J -->|Ja| K[Subagent + MCP]
    J -->|Nein| G

    style A fill:#cccccc
    style C fill:#ffff99
    style F fill:#99ff99
    style G fill:#99ccff
    style I fill:#88ff88
    style K fill:#88ccff
```

---

### Wann NICHT migrieren

#### ‚ùå Von Command zu Skill wenn:

1. **Du explizite Kontrolle willst**
   - Deployment zu Production
   - Kritische DB-Operations
   - Irreversible Actions

2. **Task ist zu simpel (1 Schritt)**
   - "Run tests"
   - "Format file"
   - Besser als Command mit voller Kontrolle

3. **Context-Window ist knapp**
   - Viele Skills = Metadata-Overhead
   - Commands werden nur on-demand geladen

4. **Skill w√ºrde selten aktiviert**
   - <5x pro Monat
   - Overhead lohnt sich nicht

---

#### ‚ùå Von Command zu Subagent wenn:

1. **Keine Parallelisierung n√∂tig**
   - Sequenzieller Workflow ist in Ordnung
   - Command ist schnell genug

2. **Context-Sharing wichtig**
   - Subagent verliert Main-Context
   - Wenn Conversation History n√∂tig

3. **Task ist zu einfach**
   - Subagent-Overhead f√ºr simple Tasks unn√∂tig

---

#### ‚ùå Von Skill zu MCP wenn:

1. **Skill l√∂st Problem bereits gut**
   - Keine externen Daten n√∂tig
   - Funktioniert mit Built-in Tools

2. **Keine externen Daten involviert**
   - Lokale Dateien ‚Üí Built-in Tools
   - Keine APIs n√∂tig

3. **Context-Window bereits voll**
   - MCP Server = Context-Window-Explosion
   - Vermeiden wenn m√∂glich

---

### Praktische Migrations-Beispiele

#### Migration 1: Logging ‚Üí Command ‚Üí Skill

**Stufe 1: Direkter Prompt**
```
User: "Add logging to handlePayment function"
Claude: Adds console.log statements
```

**Stufe 2: Slash Command (nach 5x)**
```markdown
---
name: add-logging
---
Add structured logging to function: $ARGUMENTS

1. Read function
2. Add logging at:
   - Entry (params)
   - Key steps
   - Exit (return value)
   - Errors (catch blocks)
3. Use Winston logger
```

**Stufe 3: Skill (Team-Standard)**
```markdown
---
name: Logging Enforcer
description: Add structured logging to functions. Use when creating or reviewing functions without logging.
---

# Logging Enforcer

When user creates/reviews function without logging:

1. Detect missing logging
2. Add Winston logger with proper levels:
   - info: Function entry/exit
   - debug: Key steps
   - error: Errors
3. Follow logging standards from @CLAUDE.md
```

**Warum Migration sinnvoll:**
- Team-Standard ‚Üí Alle Funktionen sollten Logging haben
- Automatische Detection ‚Üí Keine manuellen `/add-logging` Calls
- Konsistenz ‚Üí Immer gleiche Logging-Struktur

---

#### Migration 2: Component ‚Üí Command ‚Üí Skill + MCP

**Stufe 1: Direkter Prompt**
```
User: "Create Button component"
Claude: Creates Button.tsx
```

**Stufe 2: Slash Command (nach 10x)**
```markdown
---
name: create-component
---
Create React component: $ARGUMENTS

1. Component file
2. Test file
3. Storybook file
```

**Stufe 3: Skill (Automatisch)**
```markdown
---
name: Component Creator
description: Create React components with tests and stories. Use when user mentions creating a component.
---
```

**Stufe 4: + Figma MCP (Design-Integration)**
```markdown
---
name: Component Creator
description: Create React components from Figma designs.
---

1. Figma MCP: Get design specs for component
2. Create component matching design:
   - Colors from Figma
   - Spacing from Figma
   - Typography from Figma
3. Create tests
4. Create Storybook
```

**Warum Migration sinnvoll:**
- Figma als Single Source of Truth
- Automatische Design-Code Sync
- Konsistenz zwischen Design & Code

---

## ‚ùå ANTI-PATTERNS

Lerne von h√§ufigen Fehlern:

### 1. Skills f√ºr einmalige Tasks

**‚ùå Schlecht:**

```markdown
---
name: Deploy Version 2.0 to Production
description: Deploy version 2.0 to production servers
---

# One-Time Deployment

Deploy v2.0 specifically...
```

**Problem:**
- Skill ist f√ºr einmalige Action
- Wird nie wieder aktiviert
- Overhead (Progressive Disclosure) umsonst

**‚úÖ Besser:**

Slash Command oder direkter Prompt:
```
/deploy v2.0
```

**Regel:**
- Skills nur f√ºr **wiederkehrende** Tasks
- Einmalig ‚Üí Command oder Prompt

---

### 2. MCP Server f√ºr lokale Dateien

**‚ùå Schlecht:**

```json
{
  "mcpServers": {
    "local-files": {
      "command": "mcp-server-filesystem",
      "args": ["/path/to/project"]
    }
  }
}
```

**Problem:**
- MCP verursacht Context-Window-Explosion
- Built-in Tools (Read, Write, Grep, Glob) sind viel effizienter
- Unn√∂tiger Overhead

**‚úÖ Besser:**

Nutze Built-in Tools:
- `Read` f√ºr Dateien lesen
- `Write` f√ºr Dateien schreiben
- `Grep` f√ºr Suche
- `Glob` f√ºr File-Matching

**Regel:**
- MCP nur f√ºr **externe** Systeme
- Lokale Dateien ‚Üí Built-in Tools

---

### 3. Verschachtelte Subagenten

**‚ùå Schlecht:**

```markdown
# Subagent A
---
name: orchestrator
---

Start Subagent B for each task...
```

**Problem:**
- Subagenten k√∂nnen **keine** anderen Subagenten aufrufen
- Technische Limitation!

**‚úÖ Besser:**

Main Agent orchestriert beide Subagents parallel:

```markdown
# Main Agent
1. Identifiziere Tasks
2. Start Subagent A f√ºr Task 1
3. Start Subagent B f√ºr Task 2
4. Beide laufen parallel
```

**Regel:**
- Nur Main Agent kann Subagenten starten
- Subagenten sind "Leaf Nodes"

---

### 4. Skills f√ºr alles

**‚ùå Schlecht:**

```
.claude/skills/
‚îú‚îÄ‚îÄ calculate-sum/
‚îú‚îÄ‚îÄ format-date/
‚îú‚îÄ‚îÄ uppercase-string/
‚îú‚îÄ‚îÄ remove-whitespace/
‚îú‚îÄ‚îÄ validate-email/
‚îú‚îÄ‚îÄ ... (50 weitere Mini-Skills)
```

**Problem:**
- Zu viele Skills = Context-Pollution
- Metadata f√ºr ALLE Skills wird geladen (Progressive Disclosure Stufe 1)
- Claude muss alle evaluieren ‚Üí Performance-Problem

**‚úÖ Besser:**

Skills nur f√ºr **echte Domain-Expertise**:
```
.claude/skills/
‚îú‚îÄ‚îÄ brand-compliance/
‚îú‚îÄ‚îÄ api-design-reviewer/
‚îú‚îÄ‚îÄ security-audit/
‚îî‚îÄ‚îÄ qbr-creator/
```

Einfache Funktionen ‚Üí Keine Skills n√∂tig!

**Regel:**
- Skills: <20 empfohlen
- Nur f√ºr Domain-Expertise & Team-Standards
- Nicht f√ºr triviale 1-Liner

---

### 5. Slash Command Overload

**‚ùå Schlecht:**

```
.claude/commands/
‚îú‚îÄ‚îÄ add-button.md
‚îú‚îÄ‚îÄ add-input.md
‚îú‚îÄ‚îÄ add-select.md
‚îú‚îÄ‚îÄ add-checkbox.md
... (100 Commands f√ºr jedes Detail)
```

**Problem:**
- Un√ºbersichtlich
- Schwer zu finden
- Kein User kann sich 100 Commands merken

**‚úÖ Besser:**

**Option A: Gruppierung in Skills**
```
.claude/skills/
‚îî‚îÄ‚îÄ component-creator/
    ‚îú‚îÄ‚îÄ SKILL.md (orchestriert alles)
    ‚îî‚îÄ‚îÄ commands/
        ‚îú‚îÄ‚îÄ button.md
        ‚îú‚îÄ‚îÄ input.md
        ‚îî‚îÄ‚îÄ select.md
```

**Option B: Namespacing**
```
.claude/commands/
‚îú‚îÄ‚îÄ frontend:component.md
‚îú‚îÄ‚îÄ frontend:page.md
‚îú‚îÄ‚îÄ backend:api.md
‚îî‚îÄ‚îÄ backend:database.md
```

User: `/frontend:component Button`

**Regel:**
- Commands: <30 empfohlen
- Nutze Namespacing f√ºr Gruppierung
- Erw√§ge Skills f√ºr viele √§hnliche Commands

---

### 6. Hooks f√ºr komplexe Logik

**‚ùå Schlecht:**

```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/*.py)": "python complex_analysis.py $FILE && python generate_docs.py $FILE && python run_linter.py $FILE && python update_index.py && ..."
    }
  }
}
```

**Problem:**
- Hooks sind Shell-Commands, keine LLM-Logik
- Komplex = Schwer zu debuggen
- Fehler blockieren Workflow
- Keine intelligente Entscheidung

**‚úÖ Besser:**

Skill mit klarer Logik:

```markdown
---
name: Python File Processor
description: Process Python files after writing (analyze, document, lint).
---

# Python File Processor

When Python file is written:

1. Analyze with pylint
2. Generate docstrings if missing
3. Update module index
4. Check complexity (only if >50 lines)
```

**Regel:**
- Hooks: Simple Shell-Commands (Formatting, Linting)
- Komplexe Logik ‚Üí Skills (LLM kann intelligent entscheiden)

---

### 7. Alle Slash Commands zu Skills konvertieren

**‚ùå Schlecht:**

```
Massenmigration:
.claude/commands/* ‚Üí .claude/skills/*
```

**Problem:**
- Nicht jeder Command profitiert von Skill-Conversion
- Overhead ohne Nutzen
- Verlust von expliziter Kontrolle

**‚úÖ Besser:**

Nur migrieren wenn:
- ‚úÖ Wirklich wiederkehrend (>10x)
- ‚úÖ Claude soll automatisch entscheiden
- ‚úÖ Mehrere Schritte involviert
- ‚úÖ Team-Standard

**Behalte Commands f√ºr:**
- ‚ùå Kritische Operations (Deployment)
- ‚ùå Explizite Kontrolle gew√ºnscht
- ‚ùå Seltene Tasks (<5x)

**Regel:**
- Skill ‚â† automatisch besser als Command
- Commands haben ihren Platz!

---

### 8. Zu viele MCP Server

**‚ùå Schlecht:**

```json
{
  "mcpServers": {
    "jira": {...},
    "github": {...},
    "gitlab": {...},
    "salesforce": {...},
    "hubspot": {...},
    "slack": {...},
    "google-drive": {...},
    "box": {...},
    "postgres": {...},
    "mysql": {...},
    "redis": {...},
    "elasticsearch": {...}
  }
}
```

**Problem:**
- Alle MCP Tools sofort im Context Window!
- Massive Context-Window-Explosion
- Claude kann nicht effizient arbeiten

**‚úÖ Besser:**

**Option A: Nur aktiv ben√∂tigte MCP Server** (Max. 5)
```json
{
  "mcpServers": {
    "jira": {...},
    "github": {...},
    "postgres": {...}
  }
}
```

**Option B: Profile f√ºr verschiedene Workflows**

`.claude/settings.json` (Development):
```json
{
  "mcpServers": {
    "github": {...},
    "postgres": {...}
  }
}
```

`.claude/settings.business.json` (Business):
```json
{
  "mcpServers": {
    "salesforce": {...},
    "google-drive": {...}
  }
}
```

**Regel:**
- MCP Server: <5 gleichzeitig empfohlen
- Mehr = Context-Window-Problem
- Nutze Profile f√ºr verschiedene Workflows

---

### 9. Subagenten ohne klare Tool-Isolation

**‚ùå Schlecht:**

```markdown
---
name: risky-agent
tools: ["Read", "Write", "Bash", "Edit"]  # Alle Tools!
---

Do various things...
```

**Problem:**
- Kein echter Vorteil von Subagent
- Sicherheitsrisiko (Bash + Write = potentiell gef√§hrlich)
- Subagent kann alles = Keine Separation of Concerns

**‚úÖ Besser:**

Klare Tool-Isolation:

```markdown
---
name: security-scanner
tools: ["Read", "Grep", "Glob"]  # Nur Lese-Zugriff!
---

Scan for security issues (Read-Only)
```

```markdown
---
name: test-runner
tools: ["Read", "Bash"]  # Nur Tests ausf√ºhren
---

Run tests in isolation
```

**Regel:**
- Subagenten: Minimale Tools f√ºr Aufgabe
- Security: Read-Only wenn m√∂glich
- Separation of Concerns

---

### 10. Hooks die Workflow blockieren

**‚ùå Schlecht:**

```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/*.ts)": "npm run build && npm run test"  // Kann 5 Minuten dauern!
    }
  }
}
```

**Problem:**
- Hook blockiert nach JEDEM Write
- User muss 5 Min warten nach jeder Datei√§nderung
- Workflow extrem langsam

**‚úÖ Besser:**

Schnelle Hooks:
```json
{
  "hooks": {
    "PostToolUse": {
      "Write(**/*.ts)": "prettier --write $FILE && eslint --fix $FILE"  // <1 Sekunde
    }
  }
}
```

Langsame Checks ‚Üí Command oder Background:
```markdown
---
name: full-check
---

Run complete build & test suite.
(User ruft auf wenn gew√ºnscht)
```

**Regel:**
- Hooks: <5 Sekunden execution time
- Langsame Ops ‚Üí Commands (User-triggered)

---

## ‚ùì FAQ

### Tool-Auswahl

**F: Sollte ich alle meine Slash Commands zu Skills konvertieren?**

**A:** Nein! Nur wenn:
- ‚úÖ Claude soll automatisch entscheiden wann relevant
- ‚úÖ Task ist wiederkehrend mit mehreren Schritten
- ‚úÖ Team-Standard der durchgesetzt werden soll

Behalte Commands f√ºr:
- ‚ùå Kritische Operations (du willst Kontrolle)
- ‚ùå Seltene Tasks
- ‚ùå Wenn Context-Window knapp ist

---

**F: Wann brauche ich wirklich einen MCP Server?**

**A:** Nur wenn:
- ‚úÖ Externe Daten/Services involviert (Jira, Salesforce, etc.)
- ‚úÖ Authentication n√∂tig (API Keys, OAuth)
- ‚úÖ Real-time Daten gew√ºnscht

NICHT f√ºr:
- ‚ùå Lokale Dateien (nutze Built-in Tools: Read, Write)
- ‚ùå Einfache HTTP Requests (nutze Bash + curl)

---

**F: Kann ich Skills verschachteln?**

**A:** Ja, Skills k√∂nnen andere Skills aufrufen. ABER:
- ‚ö†Ô∏è Testing wird komplexer
- ‚ö†Ô∏è Debugging schwieriger
- ‚ö†Ô∏è Context-Window-Overhead
- Nutze mit Vorsicht, nur wenn wirklich n√∂tig

---

**F: Wie zuverl√§ssig sind verkettete Skills?**

**A:** Abh√§ngig von:
- **Klarheit der Skill-Descriptions:** Je klarer, desto zuverl√§ssiger
- **Context-Window-Gr√∂√üe:** Zu viele Skills = Performance-Problem
- **Testing:** Kritische Workflows sollten getestet werden

Empfehlung:
- ‚úÖ Einfache Verkettung (2-3 Skills): Meistens OK
- ‚ö†Ô∏è Komplexe Verkettung (5+ Skills): Testing erforderlich
- ‚ùå Zu viele Skills (<20 total): Context-Pollution

---

### Komposition

**F: Kann ein Skill einen Subagent aufrufen?**

**A:** Ja! Skills k√∂nnen Subagenten nutzen f√ºr Parallelisierung.

Beispiel:
```markdown
---
name: Multi-Repo Security Audit
---

# Skill orchestriert Subagenten

1. Identifiziere alle Repos
2. Pro Repo: Start Security Scanner Subagent
3. Sammle Reports
4. Aggregiere zu Dashboard
```

---

**F: Kann ein Subagent einen Skill nutzen?**

**A:** Ja, Subagenten haben Zugriff auf Skills.

Beispiel:
```markdown
---
name: feature-developer
tools: ["Read", "Write", "Bash"]
---

# Subagent kann Skills nutzen

1. Component Creator Skill (f√ºr UI)
2. API Generator Skill (f√ºr Backend)
```

---

**F: Kann ein Subagent einen anderen Subagent aufrufen?**

**A:** Nein, technische Limitation!

Nur Main Agent kann Subagenten starten. Subagenten sind "Leaf Nodes".

**Workaround:** Main Agent orchestriert beide Subagenten parallel.

---

**F: K√∂nnen Slash Commands Skills aktivieren?**

**A:** Ja, indirekt!

Wenn Slash Command Beschreibung Keywords enth√§lt die Skill matcht:

```markdown
# Command
---
name: review-security
description: Review code for security vulnerabilities
---

# Skill (aktiviert automatisch!)
---
name: Security Auditor
description: Audit code for security issues. Use when reviewing security.
---
```

Keyword "security" in Command ‚Üí Skill aktiviert!

---

### Performance

**F: Zu viele Skills = Performance-Problem?**

**A:** Ja, wegen Progressive Disclosure:

**Stufe 1 (Metadata):** Wird f√ºr ALLE Skills geladen
- Name + Description f√ºr 50 Skills = Viel Context!

**Problem:** Claude muss alle 50 Skill-Descriptions evaluieren.

**Empfehlung:** <20 Skills

**L√∂sung wenn zu viele:**
- Skills zusammenfassen (gleiche Domain)
- Seltene Skills als Commands
- Profile f√ºr verschiedene Workflows

---

**F: Zu viele MCP Server = Problem?**

**A:** JA! Gro√ües Problem:

**Context-Window-Explosion:**
- Alle MCP Tools sofort im Context Window
- 10 MCP Server mit je 20 Tools = 200 Tools im Context!

**Empfehlung:** <5 MCP Server gleichzeitig

**Vergleich:**
- Skills: Progressive Disclosure ‚Üí Context-effizient ‚úÖ
- MCP: Alle Tools sofort ‚Üí Context-intensiv ‚ùå

---

**F: Sind Subagenten schneller als sequenzielle Ausf√ºhrung?**

**A:** Nur bei echtem Parallelismus!

**Parallel = Schneller:**
```markdown
10 Tests sequenziell: 10 √ó 5 Min = 50 Min
10 Tests parallel (Subagents): ~5-7 Min
```

**Kein Vorteil wenn:**
- Nur 1 Subagent (kein Parallelismus)
- Tasks m√ºssen sequenziell sein (Abh√§ngigkeiten)

---

### Migration

**F: Wann sollte ich von Command zu Skill migrieren?**

**A:** Wenn:
- ‚úÖ Task >10x wiederholt
- ‚úÖ Claude soll automatisch erkennen
- ‚úÖ Mehrere logische Schritte
- ‚úÖ Team-Standard (alle sollten nutzen)

**Checkliste:**
- [ ] Wird h√§ufig genutzt (>10x)
- [ ] Automatische Aktivierung gew√ºnscht
- [ ] Multi-Step Workflow
- [ ] Team-Standard

Alle 4 ‚Üí Skill! Sonst: Behalte Command.

---

**F: Wann sollte ich von Skill zur√ºck zu Command migrieren?**

**A:** Wenn:
- ‚ùå Skill wird selten aktiviert (<5x/Monat)
- ‚ùå Context-Window ist knapp
- ‚ùå Du brauchst explizite Kontrolle
- ‚ùå Skill ist zu spezifisch

**Zeichen dass Skill nicht passt:**
- Skill aktiviert nicht automatisch (Description zu vage?)
- Skill aktiviert zu oft (Description zu allgemein?)
- Niemand nutzt es (zu kompliziert?)

---

**F: Kann ich Command und Skill parallel haben?**

**A:** Ja! Oft sogar empfohlen.

**Beispiel:**

Command f√ºr explizite Kontrolle:
```markdown
---
name: deploy
---
Deploy to production (manual trigger)
```

Skill f√ºr Automatisierung:
```markdown
---
name: Deployment Checker
description: Check if code is ready for deployment. Use before deploying.
---

Pre-deployment checks:
- Tests passing?
- Linting clean?
- Breaking changes documented?
```

User kann `/deploy` manuell callen, aber Skill pr√ºft automatisch vorher!

---

### Troubleshooting

**F: Skill wird nicht aktiviert obwohl relevant?**

**A:** Check Description:

**Zu vage:**
```markdown
---
description: Help with data
---
```

**Besser (spezifisch):**
```markdown
---
description: Analyze CSV and Excel files for revenue reports, pipeline analysis, and sales forecasting.
---
```

**Trigger-W√∂rter hinzuf√ºgen:**
- "Analyze CSV" ‚Üí Keywords: CSV, Excel, analyze
- "Create QBR" ‚Üí Keywords: QBR, quarterly review, business review

**Debug-Trick:**
Frag Claude: "Welche Skills sind aktiv?" ‚Üí Siehst du ob Skill erkannt wurde.

---

**F: Zu viele Skills aktivieren sich?**

**A:** Descriptions zu allgemein:

**Problem:**
```markdown
---
name: Code Helper
description: Help with code
---
```
‚Üí Aktiviert bei JEDEM Code-Request!

**L√∂sung:**
```markdown
---
name: React Component Creator
description: Create React components with TypeScript, tests, and Storybook. Use when user explicitly requests a new component.
---
```

**Spezifischer = Bessere Activation**

---

**F: Subagent verliert Context?**

**A:** Das ist normal! Subagenten sind isoliert.

**L√∂sung:** √úbergebe relevanten Context explizit:

**‚ùå Schlecht:**
```markdown
Main: "Fix the test"
‚Üí Subagent: "Which test?"
```

**‚úÖ Gut:**
```markdown
Main: "Fix test 'UserService.createUser' in src/services/UserService.test.ts
       Error: 'Expected status 201 but got 400'
       Context: We changed validation rules in last commit"
‚Üí Subagent: Hat alle Infos!
```

---

**F: MCP Server funktioniert nicht?**

**A:** H√§ufige Probleme:

**1. Authentication fehlt:**
```json
{
  "env": {
    "API_KEY": "..."  // Check: Ist Key g√ºltig?
  }
}
```

**2. Command nicht gefunden:**
```json
{
  "command": "npx",
  "args": ["-y", "@modelcontextprotocol/server-jira"]
}
```
‚Üí Check: `npx @modelcontextprotocol/server-jira` im Terminal

**3. Permissions:**
- Read-Only User f√ºr DB?
- API Token hat Permissions?

**Debug:** Check Claude Logs:
- macOS: `~/Library/Logs/Claude/`
- Windows: `%APPDATA%\Claude\logs\`

---

**F: Hook wird nicht ausgef√ºhrt?**

**A:** Check Pattern-Matching:

**‚ùå Funktioniert nicht:**
```json
{
  "PostToolUse": {
    "Write(*.ts)": "prettier $FILE"  // Fehlt **/
  }
}
```

**‚úÖ Funktioniert:**
```json
{
  "PostToolUse": {
    "Write(**/*.ts)": "prettier $FILE"  // ** = recursive
  }
}
```

**Debug:**
- F√ºge `echo` hinzu: `"echo 'Hook triggered!' && prettier $FILE"`
- Check Terminal Output

---

**F: Wie debugge ich Skill-Activation?**

**A:** Mehrere Optionen:

**1. Frag Claude direkt:**
```
User: "Welche Skills sind aktiv?"
Claude: "Currently active: [Liste von Skills]"
```

**2. Check Skill Description:**
- Sind Keywords enthalten die User verwendet?
- Ist Description spezifisch genug?

**3. Test mit explizitem Mention:**
```
User: "Use the Brand Compliance Checker to review this presentation"
‚Üí Claude sollte Skill nutzen
```

**4. Simplified Test:**
- Erstelle minimalen Test-Skill
- Check ob dieser aktiviert wird
- Dann: Erweitere schrittweise

---

### Best Practices

**F: Wie organisiere ich viele Commands/Skills?**

**A:** Empfohlene Struktur:

```
.claude/
‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îú‚îÄ‚îÄ git/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commit.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ worktree-create.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worktree-remove.md
‚îÇ   ‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ component.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.md
‚îÇ   ‚îî‚îÄ‚îÄ backend/
‚îÇ       ‚îú‚îÄ‚îÄ api.md
‚îÇ       ‚îî‚îÄ‚îÄ database.md
‚îú‚îÄ‚îÄ skills/
‚îÇ   ‚îú‚îÄ‚îÄ brand-compliance/
‚îÇ   ‚îú‚îÄ‚îÄ security-audit/
‚îÇ   ‚îî‚îÄ‚îÄ qbr-creator/
‚îî‚îÄ‚îÄ subagents/
    ‚îú‚îÄ‚îÄ security-scanner.md
    ‚îî‚îÄ‚îÄ test-fixer.md
```

**Namespacing f√ºr Commands:**
- `/git:commit`
- `/frontend:component`
- `/backend:api`

---

**F: Wie dokumentiere ich meine Tools f√ºr das Team?**

**A:** Erstelle Team-Dokumentation:

**README.md in `.claude/`:**

```markdown
# Team Claude Configuration

## Available Slash Commands

### Git Commands
- `/git:commit` - Generate conventional commit message
- `/git:worktree` - Create new worktree

### Frontend Commands
- `/frontend:component` - Create React component
- `/frontend:page` - Create new page

## Active Skills

### Brand Compliance Checker
Automatically checks brand guidelines on presentations.
**Trigger:** Mention "presentation" or "slides"

### Security Auditor
Reviews code for security issues.
**Trigger:** Mention "security" or "audit"

## MCP Servers

- **Jira:** Access issues and create tickets
- **GitHub:** Repository operations
- **Postgres:** Read-only database access
```

---

**F: Wie teste ich Skills/Commands vor Deployment?**

**A:** Testing-Strategie:

**1. Lokales Testing:**
```markdown
# In .claude/commands/test-command.md
---
name: test
---

Test command (delete after testing)
```

**2. Incremental Rollout:**
- Nur du: `.claude/commands/` (Projekt-lokal)
- Team: `~/.claude/commands/` (Global shared)

**3. Version Control:**
```bash
git add .claude/
git commit -m "feat: Add new security-audit skill"
```

**4. Dokumentation:**
- README.md mit Beispielen
- Changelog f√ºr neue Tools

---

**F: Wie verhindere ich Konflikte zwischen Tools?**

**A:** Klare Zust√§ndigkeiten:

**‚ùå Konflikt:**
```markdown
# Skill A
description: Format code

# Skill B
description: Format and lint code
```
‚Üí Beide aktivieren bei "format"!

**‚úÖ Klare Trennung:**
```markdown
# Skill A: Formatter
description: Auto-format code using Prettier/Black. Use after writing code.

# Skill B: Linter
description: Lint code for errors and style issues. Use before committing.
```

**Best Practice:**
- Jedes Tool hat klare Zust√§ndigkeit
- Keywords nicht √ºberlappen
- Test mit gleichen Prompts

---

## üîó RESSOURCEN

### Prim√§rquellen

**Video-Tutorial (Basis f√ºr diesen Guide):**
- üé• [How to choose the right approach for your task](https://www.youtube.com/watch?v=kFpLzCVLA20)
- Von: Anthropic
- Datum: Oktober 2025

**GitHub Issue:**
- üìã [Issue #7: Tool Selection Guide](https://github.com/trytofly94/Claude-Documentation/issues/7)

---

### Verwandte Dokumentation

**In diesem Repository:**

**[TOOL_INTERACTIONS.md](TOOL_INTERACTIONS.md)**
- Technische Details: **WIE** Tools interagieren
- SlashCommand Tool
- Progressive Disclosure
- Event-driven Automation
- 10 praktische Patterns
- Decision Matrix

**[CLAUDE_CODE.md](CLAUDE_CODE.md)**
- Skills: Komplette Dokumentation
- Slash Commands: Format & Syntax
- Subagenten: Configuration Details
- Hooks: PreToolUse & PostToolUse
- CLI Features

**[MCP_GUIDE.md](MCP_GUIDE.md)**
- MCP Server: Installation & Konfiguration
- Verf√ºgbare Server (Jira, GitHub, Google Drive, etc.)
- Configuration Examples
- Troubleshooting

**[WORKFLOWS.md](WORKFLOWS.md)**
- Praktische Workflows
- Best Practices
- Kombinierte Nutzung
- FAQ

**[CLAUDE_DESKTOP.md](CLAUDE_DESKTOP.md)**
- Skills API
- Box Integration
- "Imagine with Claude"

---

### Offizielle Anthropic-Dokumentation

- üìñ [Claude Code Docs](https://docs.claude.com/en/docs/claude-code)
- üîå [MCP Website](https://modelcontextprotocol.io)
- üì∞ [Anthropic Blog](https://anthropic.com/news)

---

### Community & Support

- üí¨ [Claude Discord](https://discord.gg/claude) (falls verf√ºgbar)
- üêõ [GitHub Issues](https://github.com/trytofly94/Claude-Documentation/issues)
- üìß Support: support@anthropic.com

---

## üéì Zusammenfassung

### Die wichtigsten Takeaways

#### 1. "Prompt First" Philosophie
> Fang immer einfach an: Direkter Prompt ‚Üí Slash Command ‚Üí Skill/Subagent ‚Üí +MCP

#### 2. Tool-Wahl-Matrix
- **Slash Commands:** Manuelle, wiederholbare Workflows
- **Skills:** Automatische Aktivierung, Domain-Expertise
- **Subagenten:** Parallelisierung, Tool-Isolation
- **MCP Server:** Externe Integrationen (Jira, DB, etc.)
- **Hooks:** Garantierte Automatisierung (nicht LLM)

#### 3. Context-Window ist kritisch
- **Skills:** Context-effizient (Progressive Disclosure) ‚úÖ
- **MCP Server:** Context-intensiv (alle Tools sofort) ‚ö†Ô∏è
- **Empfehlung:** <20 Skills, <5 MCP Server

#### 4. Kompositionshierarchie
```
Skills/Commands (top)
  ‚Üì
MCP Server + Subagenten (middle)
  ‚Üì
Hooks + Built-in Tools (bottom)
```

#### 5. Anti-Patterns vermeiden
- ‚ùå Skills f√ºr einmalige Tasks
- ‚ùå MCP f√ºr lokale Dateien
- ‚ùå Verschachtelte Subagenten
- ‚ùå Zu viele Skills/MCP Server

#### 6. Testing & Iteration
- Start einfach ‚Üí Teste ‚Üí Skaliere bei Bedarf
- Dokumentiere f√ºr Team
- Version Control f√ºr `.claude/`

---

### N√§chste Schritte

1. **Verstehe deine Anforderungen**
   - Einmalig oder wiederkehrend?
   - Manuell oder automatisch?
   - Parallel n√∂tig?
   - Externe Daten?

2. **Nutze den Entscheidungsbaum** (siehe oben)

3. **Start mit Slash Command**
   - Test die Idee
   - Iteriere

4. **Migriere wenn sinnvoll**
   - Command ‚Üí Skill (wenn automatisch gew√ºnscht)
   - Command ‚Üí Subagent (wenn parallel n√∂tig)
   - + MCP (wenn externe Daten)

5. **Dokumentiere & Teile**
   - README.md in `.claude/`
   - Onboarding f√ºr Team

---

**Viel Erfolg beim Tool-Auswahl! üöÄ**

Bei Fragen: [GitHub Issues](https://github.com/trytofly94/Claude-Documentation/issues)

---

**Stand:** 4. November 2025
**Version:** 1.0
**Autoren:** trytofly94 + Claude (Sonnet 4.5)
**Lizenz:** MIT
